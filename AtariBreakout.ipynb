{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Learn Atari Breakout\n",
    "\n",
    "This notebook contains the source code from the YouTube video [Neural Network Learns To Play Atari Breakout](url_here) and walks you through how to define a neural network in Tensorflow 2.0 and Pytorch and train it to learn to play Atari Breakout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "Import the libraries that are needed for loading the Breakout Unity game ([mlagents](https://github.com/Unity-Technologies/ml-agents)), defining the Tensorflow 2.0 neural network ([tensorflow](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf)) and the Pytorch version ([torch](https://pytorch.org/docs/stable/index.html)). Note that the ML-Agents library requires [Python 3.6](https://www.python.org/downloads/release/python-368/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q mlagents==0.7\n",
    "!pip3 install -q tensorflow==2.0.0-alpha0\n",
    "!pip3 install -q torch==1.0.1.post2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Unity Environment\n",
    "\n",
    "The next step is to load the Breakout environment as a `UnityEnvironment` object which launches and begins communication with the Unity game executable when instantiated. The `unity_env` variable is the handle for sending agent actions to the game and receiving resulting next/terminal states and rewards at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlagents.envs:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 2\n",
      "        Number of Training Brains : 1\n",
      "        Reset Parameters :\n",
      "\t\tepisode -> 0.0\n",
      "Unity brain name: BreakoutLearning\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space size (per agent): 54\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): [3]\n",
      "        Vector Action descriptions: \n",
      "Unity brain name: BreakoutPlayer\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space size (per agent): 54\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): [3]\n",
      "        Vector Action descriptions: \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import numpy as np\n",
    "from mlagents.envs import UnityEnvironment\n",
    "\n",
    "unity_files = {\"Linux\": \"./env/linux/Breakout\", \"Darwin\": \"./env/mac/Breakout\", \"Windows\": \"./env/windows/Breakout\"}\n",
    "unity_file = unity_files[platform.system()]\n",
    "unity_env = UnityEnvironment(file_name=unity_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlagents.envs:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 2\n",
      "        Number of Training Brains : 1\n",
      "        Reset Parameters :\n",
      "\t\tepisode -> 0.0\n",
      "Unity brain name: BreakoutLearning\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space size (per agent): 54\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): [3]\n",
      "        Vector Action descriptions: \n",
      "Unity brain name: BreakoutPlayer\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space size (per agent): 54\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): [3]\n",
      "        Vector Action descriptions: \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import numpy as np\n",
    "from mlagents.envs import UnityEnvironment\n",
    "\n",
    "unity_files = {\"Linux\": \"./env/linux/Breakout\", \"Darwin\": \"./env/mac/Breakout\", \"Windows\": \"./env/windows/Breakout\"}\n",
    "unity_file = unity_files[platform.system()]\n",
    "unity_env = UnityEnvironment(file_name=unity_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create OpenAI Gym Wrapper for Unity Environment\n",
    "\n",
    "As most people are more familiar with the gym API of [OpenAI Gym](https://gym.openai.com/docs/) for communicating with an environment, we will create a wrapper class `GymEnvironment` that mimics the OpenAI Gym environment functions for resetting and stepping through an environment. You can also do any preprocessing of states returned from the environment or adjust the reward signal.\n",
    "\n",
    "- For more info, check out this tutorial video for [Getting Started with OpenAI Gym](https://www.youtube.com/watch?v=8MC3y7ASoPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GymEnvironment():\n",
    "    def __init__(self, unity_env):\n",
    "        self.env = unity_env\n",
    "        self.default_brain = unity_env.brain_names[0]\n",
    "        self.observation_space_size = unity_env.brains[self.default_brain].vector_observation_space_size\n",
    "        self.action_space_size = int(unity_env.brains[self.default_brain].vector_action_space_size[0])\n",
    "        \n",
    "    def reset(self, train_mode=True):\n",
    "        self.env_info = self.env.reset(train_mode=train_mode)[self.default_brain]\n",
    "        return self.env_info.vector_observations[0]\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.env_info = self.env.step(action)[self.default_brain]\n",
    "        next_state = self.env_info.vector_observations[0]\n",
    "        reward = self.env_info.rewards[0]\n",
    "        done = self.env_info.local_done[0]\n",
    "        return next_state, reward, done, self.env_info\n",
    "    \n",
    "    def close(self):\n",
    "        self.env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Understand the Breakout Environment\n",
    "\n",
    "We can reset the environment to be provided with an initial set of states for the agent in the environment. The `action_size` variable holds the number of actions that the agent can choose from. _states_ refer to a vector of variables corresponding to relevant aspects of the environment that the agent 'sees'.\n",
    "\n",
    "\n",
    "![AtariBreakout](./AtariBreakout.png)\n",
    "\n",
    "\n",
    "In the breakout environment, the agent is controlling a paddle at the bottom of the screen and can between 3 actions: to move it left, right or no movement. Its goal is to hit the ball to destroy all the floating bricks and prevent the ball from falling to the bottom. It will get a reward of +1 whenever the ball hits a brick and -1 for each brick remaining if the ball falls to the bottom.\n",
    "\n",
    "The state consists of 54 numbers where the first two are the ball's `x` and `y` position, the next two are the ball's `x` and `y` velocity, the next two are the paddle's `x` position and `x` velocity and the remaining 48 represent each brick's status of destroyed (0.) or remaining (1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions: 3\n",
      "States have length: 54\n",
      "States look like: [ 0.          0.         -2.77063155  5.3219924   0.          0.\n",
      "  1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "env = GymEnvironment(unity_env)\n",
    "action_size = env.action_space_size\n",
    "state_size = env.observation_space_size\n",
    "state = env.reset()\n",
    "\n",
    "print('Number of actions:', action_size)\n",
    "print('States have length:', state_size)\n",
    "print('States look like:', state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the Reinforcement Learning Components\n",
    "\n",
    "The next step is to define the components that make up the reinforcement learning algorithm. This requires defining:\n",
    "\n",
    "- **3.1** The neural network architecture to approximate the Q function.\n",
    "- **3.2** The experience replay buffer for storing and sampling batches of experience tuples.\n",
    "- **3.3** The Q-Learning agent that samples from the replay buffer and trains the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.0 Neural Network Hyperparameters\n",
    "\n",
    "These are the settings for the neural network that we need to tweak to suit our particular task of playing Breakout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 800             # Specifies the number of nodes in each layer of the network\n",
    "LEARNING_RATE = 0.00002       # Sets how much we want to update the network weights at each training step\n",
    "REGULARIZER_LAMBDA = 1e-6     # Penalty multiplier to apply for the size of the network weights\n",
    "TARGET_UPDATE_RATE = 0.0004   # How frequently we want to copy the local network to the target network (for double DQNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3.1.1 Tensorflow QNetwork\n",
    "\n",
    "Below is the implementation of a Deep Q Network using TensorFlow 2.0 as the backend model. The `TFModel` class defines the actual neural network architecture for approximating the Q-function and the `TFQNetwork` incorporates the neural network to define a function for retrieving the output q-values from an input state (`get_q_state`) and also a function for training the neural network (`optimize`).\n",
    "\n",
    "Resources:\n",
    "- A tutorial video on [Getting Started with Tensorflow 2.0](https://www.youtube.com/watch?v=fQCKxzHvYnw)\n",
    "- A tutorial video on [Basic Deep Q Network (DQN) in Tensorflow](https://www.youtube.com/watch?v=dpBKz1wxE_c)\n",
    "- A tutorial video on [Upgrading a DQN to a Double DQN](https://www.youtube.com/watch?v=ILDLT97FsNM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/anaconda3/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/anaconda3/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: dlopen(/anaconda3/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _clock_gettime\n  Referenced from: /anaconda3/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so (which was built for Mac OS X 10.13)\n  Expected in: /usr/lib/libSystem.B.dylib\n in /anaconda3/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/anaconda3/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _clock_gettime\n  Referenced from: /anaconda3/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so (which was built for Mac OS X 10.13)\n  Expected in: /usr/lib/libSystem.B.dylib\n in /anaconda3/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-951142b44971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensorflow:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTFModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/_api/v2/audio/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_print_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_audio_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecode_wav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_audio_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mencode_wav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/anaconda3/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/anaconda3/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: dlopen(/anaconda3/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _clock_gettime\n  Referenced from: /anaconda3/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so (which was built for Mac OS X 10.13)\n  Expected in: /usr/lib/libSystem.B.dylib\n in /anaconda3/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow:\", tf.__version__)\n",
    "\n",
    "class TFModel(tf.keras.Model):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super().__init__()\n",
    "        self.hidden1 = tf.keras.layers.Dense(HIDDEN_SIZE, activation=tf.nn.relu, kernel_initializer=tf.initializers.glorot_normal())\n",
    "        self.hidden2 = tf.keras.layers.Dense(HIDDEN_SIZE, activation=tf.nn.relu, kernel_initializer=tf.initializers.glorot_normal(), kernel_regularizer=tf.keras.regularizers.l2(l=REGULARIZER_LAMBDA))\n",
    "        self.q_state = tf.keras.layers.Dense(action_size, activation=None, kernel_initializer=tf.initializers.glorot_normal())\n",
    "        \n",
    "    def call(self, state):\n",
    "        hidden1 = self.hidden1(state)\n",
    "        hidden2 = self.hidden2(hidden1) + hidden1\n",
    "        q_state = self.q_state(hidden2)\n",
    "        return q_state\n",
    "    \n",
    "class TFQNetwork():\n",
    "    def __init__(self, state_size, action_size, load=False):\n",
    "        self.model_local = TFModel(state_size, action_size)\n",
    "        self.model_target = TFModel(state_size, action_size)\n",
    "        self.optimizer = tf.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "        self.action_size = action_size\n",
    "        if load: self.load_model()\n",
    "        \n",
    "    def get_q_state(self, state, use_target=False):\n",
    "        model = self.model_local if not use_target else self.model_target\n",
    "        return model(np.array(state)).numpy()\n",
    "    \n",
    "    def get_loss(self, states, actions, q_targets):\n",
    "        actions_one_hot = tf.one_hot(actions, depth=self.action_size)\n",
    "        q_states = tf.cast(self.model_local(states), tf.float32)\n",
    "        q_states_actions = tf.reduce_sum(tf.multiply(q_states, actions_one_hot), axis=1)\n",
    "        loss = tf.reduce_sum(tf.square(q_states_actions - q_targets))\n",
    "        return loss\n",
    "    \n",
    "    def optimize(self, states, actions, q_targets):\n",
    "        loss = lambda: self.get_loss(states, actions, q_targets)\n",
    "        self.optimizer.minimize(loss=loss, var_list=self.model_local.trainable_weights)\n",
    "        self.soft_copy(self.model_local, self.model_target)\n",
    "        \n",
    "    def soft_copy(self, local, target, tau=TARGET_UPDATE_RATE):\n",
    "        new_target_vars = [t + tau*(l-t) for l,t in zip(local.get_weights(), target.get_weights())]\n",
    "        self.model_target.set_weights(new_target_vars)\n",
    "        \n",
    "    def save_model(self, filepath=\"./saved_models/tensorflow2/model.tf\"):\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        self.model_local.save_weights(filepath)\n",
    "        \n",
    "    def load_model(self, filepath=\"./saved_models/tensorflow2/model.tf\"):\n",
    "        if os.path.exists(filepath + \".index\"):\n",
    "            self.model_local.load_weights(filepath)\n",
    "            self.model_target.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 PyTorch QNetwork\n",
    "\n",
    "Below is the implementation of a QNetwork using PyTorch as the backend model. The `PTModel` class defines the actual neural network architecture for approximating the Q-function and the `PTQNetwork` is the equivalent of the `TFQNetwork` adapted for PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "\n",
    "class PTModel(torch.nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super().__init__()\n",
    "        self.hidden1 = torch.nn.Linear(state_size, HIDDEN_SIZE)\n",
    "        self.hidden2 = torch.nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
    "        self.q_state = torch.nn.Linear(HIDDEN_SIZE, action_size)\n",
    "        torch.nn.init.xavier_normal_(self.hidden1.weight)\n",
    "        torch.nn.init.xavier_normal_(self.hidden2.weight)\n",
    "        torch.nn.init.xavier_normal_(self.q_state.weight)\n",
    "\n",
    "    def forward(self, state):\n",
    "        hidden1 = torch.nn.functional.relu(self.hidden1(state))\n",
    "        hidden2 = torch.nn.functional.relu(self.hidden2(hidden1)) + hidden1\n",
    "        q_state = self.q_state(hidden2)\n",
    "        return q_state\n",
    "\n",
    "class PTQNetwork():\n",
    "    def __init__(self, state_size, action_size, load=False):\n",
    "        self.model_local = PTModel(state_size, action_size)\n",
    "        self.model_target = PTModel(state_size, action_size)\n",
    "        self.optimizer = torch.optim.Adam(self.model_local.parameters(), lr=LEARNING_RATE, weight_decay=REGULARIZER_LAMBDA)\n",
    "        if load: self.load_model()\n",
    "\n",
    "    def get_q_state(self, state, use_target=False):\n",
    "        model = self.model_local if not use_target else self.model_target\n",
    "        state = torch.from_numpy(np.array(state)).float()\n",
    "        return model(state).detach().numpy()\n",
    "    \n",
    "    def get_loss(self, states, actions, q_targets):\n",
    "        states = torch.from_numpy(np.vstack(states)).float()\n",
    "        actions = torch.from_numpy(np.vstack(actions)).long()\n",
    "        q_targets = torch.from_numpy(np.vstack(q_targets)).float()\n",
    "        q_states_actions = self.model_local(states).gather(1, actions)\n",
    "        loss = (q_states_actions - q_targets)**2\n",
    "        return loss.mean()\n",
    "    \n",
    "    def optimize(self, states, actions, q_targets):\n",
    "        loss = self.get_loss(states, actions, q_targets)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.soft_copy(self.model_local, self.model_target)\n",
    "        \n",
    "    def soft_copy(self, local, target, tau=TARGET_UPDATE_RATE):\n",
    "        for l,t in zip(local.parameters(), target.parameters()):\n",
    "            t.data.copy_(t.data + tau*(l.data - t.data))\n",
    "        \n",
    "    def save_model(self, filepath=\"./saved_models/pytorch/checkpoint.pth\"):\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        torch.save(self.model_local.state_dict(), filepath)\n",
    "        \n",
    "    def load_model(self, filepath=\"./saved_models/pytorch/checkpoint.pth\"):\n",
    "        if os.path.exists(filepath):\n",
    "            self.model_local.load_state_dict(torch.load(filepath))\n",
    "            self.model_target.load_state_dict(torch.load(filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Experience Replay\n",
    "\n",
    "Below is the implementation of a Replay Buffer using the `deque` collection as the rolling buffer of experience tuples. This can be sampled by specifying the sample size and then returns each individual experience type as separate lists.\n",
    "\n",
    "- Check out this tutorial video on [How Experience Replay Works](https://www.youtube.com/watch?v=lQB08wcuCeM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, maxlen):\n",
    "        self.buffer = deque(maxlen=maxlen)\n",
    "        \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        sample_size = min(len(self.buffer), batch_size)\n",
    "        samples = random.choices(self.buffer, k=sample_size)\n",
    "        return map(list, zip(*samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Q-Learning Algorithm\n",
    "\n",
    "This step implements the final AI agent that uses Deep Q Networks to learn the Bellman equation for selecting actions to take in a given state from the environment. It instantiates a QNetwork of the specified implementation (`TFQNetwork` or `PTQNetwork`) as well as the `ReplayBuffer` for experience replay.\n",
    "\n",
    "- Check out this tutorial video for [Q-Learning with the Bellman Equation](https://www.youtube.com/watch?v=wN3rxIKmMgE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.0 Q-Learning Hyperparameters\n",
    "\n",
    "Here we define the settings for the training of the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_BUFFER_SIZE = 1000000   # Sets the maximum length of the replay buffer\n",
    "REPLAY_BATCH_SIZE = 32      # How many experience tuples to sample from the buffer for each train step\n",
    "DISCOUNT_RATE = 0.99        # The constant gamma for discounting future rewards in the Bellman Equation\n",
    "EPS_MAX = 1.0               # The starting proportion of random to greedy actions to take\n",
    "EPS_MIN = 0.1               # The lower limit proportion of random to greedy actions to take\n",
    "EPS_DECAY = 0.998           # The rate at which eps decays from EPS_MAX to EPS_MIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Q-Learning Agent\n",
    "\n",
    "The `get_action` function infers an action from the QNetwork from a given state using an epsilon-greedy policy for choosing a random action more often at the start of training for exploration, and then selecting the greedy action more often later in training as the network's approximation of the Q-Function (Bellman Equation) improves.\n",
    "\n",
    "The `train` function calculates the target Q-value (`q_target`) for the `reward` from the `action` taken in the given `state` and then trains the QNetwork toward that value for the input state and action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TFQNetwork' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ec20d556acf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTFQNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPS_MAX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-ec20d556acf9>\u001b[0m in \u001b[0;36mDQNAgent\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTFQNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPS_MAX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TFQNetwork' is not defined"
     ]
    }
   ],
   "source": [
    "class DQNAgent():\n",
    "    def __init__(self, state_size, action_size, network=TFQNetwork, eps=EPS_MAX, load=False):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.q_network = network(state_size, action_size, load)\n",
    "        self.replay_buffer = ReplayBuffer(MAX_BUFFER_SIZE)\n",
    "        self.gamma = DISCOUNT_RATE\n",
    "        self.eps = eps\n",
    "\n",
    "    def get_action(self, state, eps=None):\n",
    "        eps = self.eps if eps == None else eps\n",
    "        action_greedy = np.argmax(self.q_network.get_q_state([state]))\n",
    "        action_random = np.random.randint(self.action_size)\n",
    "        action = action_random if random.random() < eps else action_greedy\n",
    "        return action\n",
    "        \n",
    "    def train(self, state, action, next_state, reward, done):\n",
    "        self.replay_buffer.add((state, action, next_state, reward, done))\n",
    "        states, actions, next_states, rewards, dones = self.replay_buffer.sample(REPLAY_BATCH_SIZE)\n",
    "        \n",
    "        next_actions = np.argmax(self.q_network.get_q_state(next_states, use_target=False), axis=1)\n",
    "        q_next_states = self.q_network.get_q_state(next_states, use_target=True)\n",
    "        q_next_states[dones] = np.zeros([self.action_size])\n",
    "        q_next_states_next_actions = q_next_states[np.arange(next_actions.shape[0]), next_actions]\n",
    "        q_targets = rewards + self.gamma * q_next_states_next_actions\n",
    "        self.q_network.optimize(states, actions, q_targets)\n",
    "\n",
    "        if done: self.eps = max(self.eps * EPS_DECAY, EPS_MIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Agent\n",
    "\n",
    "Below is the training loop for training the agent through a number of episodes of interacting with the environment. It keeps track of the total reward from each episode and also stores the last 100 episode rewards for calculating the average reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Score: -44.0, Avg reward: -44.00\n",
      "Episode: 1, Score: -46.0, Avg reward: -45.00\n",
      "Episode: 2, Score: -44.0, Avg reward: -44.67\n",
      "Episode: 3, Score: -48.0, Avg reward: -45.50\n",
      "Episode: 4, Score: -48.0, Avg reward: -46.00\n",
      "Episode: 5, Score: -48.0, Avg reward: -46.33\n",
      "Episode: 6, Score: -32.0, Avg reward: -44.29\n",
      "Episode: 7, Score: -42.0, Avg reward: -44.00\n",
      "Episode: 8, Score: -48.0, Avg reward: -44.44\n",
      "Episode: 9, Score: -44.0, Avg reward: -44.40\n",
      "Episode: 10, Score: -48.0, Avg reward: -44.73\n",
      "Episode: 11, Score: -44.0, Avg reward: -44.67\n",
      "Episode: 12, Score: -36.0, Avg reward: -44.00\n",
      "Episode: 13, Score: -48.0, Avg reward: -44.29\n",
      "Episode: 14, Score: -44.0, Avg reward: -44.27\n",
      "Episode: 15, Score: -48.0, Avg reward: -44.50\n",
      "Episode: 16, Score: -48.0, Avg reward: -44.71\n",
      "Episode: 17, Score: -46.0, Avg reward: -44.78\n",
      "Episode: 18, Score: -38.0, Avg reward: -44.42\n",
      "Episode: 19, Score: -42.0, Avg reward: -44.30\n",
      "Episode: 20, Score: -48.0, Avg reward: -44.48\n",
      "Episode: 21, Score: -42.0, Avg reward: -44.36\n",
      "Episode: 22, Score: -42.0, Avg reward: -44.26\n",
      "Episode: 23, Score: -48.0, Avg reward: -44.42\n",
      "Episode: 24, Score: -48.0, Avg reward: -44.56\n",
      "Episode: 25, Score: -46.0, Avg reward: -44.62\n",
      "Episode: 26, Score: -46.0, Avg reward: -44.67\n",
      "Episode: 27, Score: -42.0, Avg reward: -44.57\n",
      "Episode: 28, Score: -42.0, Avg reward: -44.48\n",
      "Episode: 29, Score: -48.0, Avg reward: -44.60\n",
      "Episode: 30, Score: -46.0, Avg reward: -44.65\n",
      "Episode: 31, Score: -48.0, Avg reward: -44.75\n",
      "Episode: 32, Score: -46.0, Avg reward: -44.79\n",
      "Episode: 33, Score: -44.0, Avg reward: -44.76\n",
      "Episode: 34, Score: -38.0, Avg reward: -44.57\n",
      "Episode: 35, Score: -30.0, Avg reward: -44.17\n",
      "Episode: 36, Score: -44.0, Avg reward: -44.16\n",
      "Episode: 37, Score: -44.0, Avg reward: -44.16\n",
      "Episode: 38, Score: -44.0, Avg reward: -44.15\n",
      "Episode: 39, Score: -48.0, Avg reward: -44.25\n",
      "Episode: 40, Score: -46.0, Avg reward: -44.29\n",
      "Episode: 41, Score: -40.0, Avg reward: -44.19\n",
      "Episode: 42, Score: -42.0, Avg reward: -44.14\n",
      "Episode: 43, Score: -48.0, Avg reward: -44.23\n",
      "Episode: 44, Score: -48.0, Avg reward: -44.31\n",
      "Episode: 45, Score: -48.0, Avg reward: -44.39\n",
      "Episode: 46, Score: -46.0, Avg reward: -44.43\n",
      "Episode: 47, Score: -4.0, Avg reward: -43.58\n",
      "Episode: 48, Score: -48.0, Avg reward: -43.67\n",
      "Episode: 49, Score: -40.0, Avg reward: -43.60\n",
      "Episode: 50, Score: -48.0, Avg reward: -43.69\n",
      "Episode: 51, Score: -46.0, Avg reward: -43.73\n",
      "Episode: 52, Score: -46.0, Avg reward: -43.77\n",
      "Episode: 53, Score: -46.0, Avg reward: -43.81\n",
      "Episode: 54, Score: -48.0, Avg reward: -43.89\n",
      "Episode: 55, Score: -46.0, Avg reward: -43.93\n",
      "Episode: 56, Score: -44.0, Avg reward: -43.93\n",
      "Episode: 57, Score: -48.0, Avg reward: -44.00\n",
      "Episode: 58, Score: -44.0, Avg reward: -44.00\n",
      "Episode: 59, Score: -46.0, Avg reward: -44.03\n",
      "Episode: 60, Score: -48.0, Avg reward: -44.10\n",
      "Episode: 61, Score: -44.0, Avg reward: -44.10\n",
      "Episode: 62, Score: -44.0, Avg reward: -44.10\n",
      "Episode: 63, Score: -48.0, Avg reward: -44.16\n",
      "Episode: 64, Score: -48.0, Avg reward: -44.22\n",
      "Episode: 65, Score: -46.0, Avg reward: -44.24\n",
      "Episode: 66, Score: -42.0, Avg reward: -44.21\n",
      "Episode: 67, Score: -44.0, Avg reward: -44.21\n",
      "Episode: 68, Score: -46.0, Avg reward: -44.23\n",
      "Episode: 69, Score: -44.0, Avg reward: -44.23\n",
      "Episode: 70, Score: -46.0, Avg reward: -44.25\n",
      "Episode: 71, Score: -48.0, Avg reward: -44.31\n",
      "Episode: 72, Score: -48.0, Avg reward: -44.36\n",
      "Episode: 73, Score: -42.0, Avg reward: -44.32\n",
      "Episode: 74, Score: -44.0, Avg reward: -44.32\n",
      "Episode: 75, Score: -48.0, Avg reward: -44.37\n",
      "Episode: 76, Score: -38.0, Avg reward: -44.29\n",
      "Episode: 77, Score: -38.0, Avg reward: -44.21\n",
      "Episode: 78, Score: -46.0, Avg reward: -44.23\n",
      "Episode: 79, Score: -48.0, Avg reward: -44.27\n",
      "Episode: 80, Score: -46.0, Avg reward: -44.30\n",
      "Episode: 81, Score: -46.0, Avg reward: -44.32\n",
      "Episode: 82, Score: -48.0, Avg reward: -44.36\n",
      "Episode: 83, Score: -44.0, Avg reward: -44.36\n",
      "Episode: 84, Score: -46.0, Avg reward: -44.38\n",
      "Episode: 85, Score: -46.0, Avg reward: -44.40\n",
      "Episode: 86, Score: -46.0, Avg reward: -44.41\n",
      "Episode: 87, Score: -46.0, Avg reward: -44.43\n",
      "Episode: 88, Score: -42.0, Avg reward: -44.40\n",
      "Episode: 89, Score: -48.0, Avg reward: -44.44\n",
      "Episode: 90, Score: -14.0, Avg reward: -44.11\n",
      "Episode: 91, Score: -46.0, Avg reward: -44.13\n",
      "Episode: 92, Score: -48.0, Avg reward: -44.17\n",
      "Episode: 93, Score: -46.0, Avg reward: -44.19\n",
      "Episode: 94, Score: -48.0, Avg reward: -44.23\n",
      "Episode: 95, Score: -48.0, Avg reward: -44.27\n",
      "Episode: 96, Score: -46.0, Avg reward: -44.29\n",
      "Episode: 97, Score: -42.0, Avg reward: -44.27\n",
      "Episode: 98, Score: -38.0, Avg reward: -44.20\n",
      "Episode: 99, Score: -44.0, Avg reward: -44.20\n",
      "Episode: 100, Score: -42.0, Avg reward: -44.18\n",
      "Episode: 101, Score: -48.0, Avg reward: -44.20\n",
      "Episode: 102, Score: -42.0, Avg reward: -44.18\n",
      "Episode: 103, Score: -46.0, Avg reward: -44.16\n",
      "Episode: 104, Score: -48.0, Avg reward: -44.16\n",
      "Episode: 105, Score: -46.0, Avg reward: -44.14\n",
      "Episode: 106, Score: -42.0, Avg reward: -44.24\n",
      "Episode: 107, Score: -48.0, Avg reward: -44.30\n",
      "Episode: 108, Score: -34.0, Avg reward: -44.16\n",
      "Episode: 109, Score: -48.0, Avg reward: -44.20\n",
      "Episode: 110, Score: -40.0, Avg reward: -44.12\n",
      "Episode: 111, Score: -48.0, Avg reward: -44.16\n",
      "Episode: 112, Score: -42.0, Avg reward: -44.22\n",
      "Episode: 113, Score: -44.0, Avg reward: -44.18\n",
      "Episode: 114, Score: -44.0, Avg reward: -44.18\n",
      "Episode: 115, Score: -42.0, Avg reward: -44.12\n",
      "Episode: 116, Score: -46.0, Avg reward: -44.10\n",
      "Episode: 117, Score: -46.0, Avg reward: -44.10\n",
      "Episode: 118, Score: -46.0, Avg reward: -44.18\n",
      "Episode: 119, Score: -42.0, Avg reward: -44.18\n",
      "Episode: 120, Score: -46.0, Avg reward: -44.16\n",
      "Episode: 121, Score: -42.0, Avg reward: -44.16\n",
      "Episode: 122, Score: -42.0, Avg reward: -44.16\n",
      "Episode: 123, Score: -44.0, Avg reward: -44.12\n",
      "Episode: 124, Score: -48.0, Avg reward: -44.12\n",
      "Episode: 125, Score: -46.0, Avg reward: -44.12\n",
      "Episode: 126, Score: -48.0, Avg reward: -44.14\n",
      "Episode: 127, Score: -48.0, Avg reward: -44.20\n",
      "Episode: 128, Score: -48.0, Avg reward: -44.26\n",
      "Episode: 129, Score: -44.0, Avg reward: -44.22\n",
      "Episode: 130, Score: -46.0, Avg reward: -44.22\n",
      "Episode: 131, Score: -42.0, Avg reward: -44.16\n",
      "Episode: 132, Score: -46.0, Avg reward: -44.16\n",
      "Episode: 133, Score: -46.0, Avg reward: -44.18\n",
      "Episode: 134, Score: -44.0, Avg reward: -44.24\n",
      "Episode: 135, Score: -42.0, Avg reward: -44.36\n",
      "Episode: 136, Score: -44.0, Avg reward: -44.36\n",
      "Episode: 137, Score: -44.0, Avg reward: -44.36\n",
      "Episode: 138, Score: -48.0, Avg reward: -44.40\n",
      "Episode: 139, Score: -46.0, Avg reward: -44.38\n",
      "Episode: 140, Score: -48.0, Avg reward: -44.40\n",
      "Episode: 141, Score: -48.0, Avg reward: -44.48\n",
      "Episode: 142, Score: -44.0, Avg reward: -44.50\n",
      "Episode: 143, Score: -42.0, Avg reward: -44.44\n",
      "Episode: 144, Score: -48.0, Avg reward: -44.44\n",
      "Episode: 145, Score: -44.0, Avg reward: -44.40\n",
      "Episode: 146, Score: -44.0, Avg reward: -44.38\n",
      "Episode: 147, Score: -44.0, Avg reward: -44.78\n",
      "Episode: 148, Score: -44.0, Avg reward: -44.74\n",
      "Episode: 149, Score: -38.0, Avg reward: -44.72\n",
      "Episode: 150, Score: -48.0, Avg reward: -44.72\n",
      "Episode: 151, Score: -48.0, Avg reward: -44.74\n",
      "Episode: 152, Score: -48.0, Avg reward: -44.76\n",
      "Episode: 153, Score: -46.0, Avg reward: -44.76\n",
      "Episode: 154, Score: -42.0, Avg reward: -44.70\n",
      "Episode: 155, Score: -46.0, Avg reward: -44.70\n",
      "Episode: 156, Score: -42.0, Avg reward: -44.68\n",
      "Episode: 157, Score: -42.0, Avg reward: -44.62\n",
      "Episode: 158, Score: -48.0, Avg reward: -44.66\n",
      "Episode: 159, Score: -48.0, Avg reward: -44.68\n",
      "Episode: 160, Score: -48.0, Avg reward: -44.68\n",
      "Episode: 161, Score: -48.0, Avg reward: -44.72\n",
      "Episode: 162, Score: -48.0, Avg reward: -44.76\n",
      "Episode: 163, Score: -46.0, Avg reward: -44.74\n",
      "Episode: 164, Score: -48.0, Avg reward: -44.74\n",
      "Episode: 165, Score: -44.0, Avg reward: -44.72\n",
      "Episode: 166, Score: -44.0, Avg reward: -44.74\n",
      "Episode: 167, Score: -42.0, Avg reward: -44.72\n",
      "Episode: 168, Score: -48.0, Avg reward: -44.74\n",
      "Episode: 169, Score: -4.0, Avg reward: -44.34\n",
      "Episode: 170, Score: -48.0, Avg reward: -44.36\n",
      "Episode: 171, Score: -42.0, Avg reward: -44.30\n",
      "Episode: 172, Score: -48.0, Avg reward: -44.30\n",
      "Episode: 173, Score: -46.0, Avg reward: -44.34\n",
      "Episode: 174, Score: -48.0, Avg reward: -44.38\n",
      "Episode: 175, Score: -48.0, Avg reward: -44.38\n",
      "Episode: 176, Score: -46.0, Avg reward: -44.46\n",
      "Episode: 177, Score: -48.0, Avg reward: -44.56\n",
      "Episode: 178, Score: -44.0, Avg reward: -44.54\n",
      "Episode: 179, Score: -44.0, Avg reward: -44.50\n",
      "Episode: 180, Score: -46.0, Avg reward: -44.50\n",
      "Episode: 181, Score: -46.0, Avg reward: -44.50\n",
      "Episode: 182, Score: -46.0, Avg reward: -44.48\n",
      "Episode: 183, Score: -48.0, Avg reward: -44.52\n",
      "Episode: 184, Score: -42.0, Avg reward: -44.48\n",
      "Episode: 185, Score: -14.0, Avg reward: -44.16\n",
      "Episode: 186, Score: -46.0, Avg reward: -44.16\n",
      "Episode: 187, Score: -48.0, Avg reward: -44.18\n",
      "Episode: 188, Score: -48.0, Avg reward: -44.24\n",
      "Episode: 189, Score: -46.0, Avg reward: -44.22\n",
      "Episode: 190, Score: -46.0, Avg reward: -44.54\n",
      "Episode: 191, Score: -42.0, Avg reward: -44.50\n",
      "Episode: 192, Score: -46.0, Avg reward: -44.48\n",
      "Episode: 193, Score: -48.0, Avg reward: -44.50\n",
      "Episode: 194, Score: -46.0, Avg reward: -44.48\n",
      "Episode: 195, Score: -44.0, Avg reward: -44.44\n",
      "Episode: 196, Score: -46.0, Avg reward: -44.44\n",
      "Episode: 197, Score: -48.0, Avg reward: -44.50\n",
      "Episode: 198, Score: -46.0, Avg reward: -44.58\n",
      "Episode: 199, Score: -46.0, Avg reward: -44.60\n",
      "Episode: 200, Score: -44.0, Avg reward: -44.62\n",
      "Episode: 201, Score: -38.0, Avg reward: -44.52\n",
      "Episode: 202, Score: -48.0, Avg reward: -44.58\n",
      "Episode: 203, Score: -46.0, Avg reward: -44.58\n",
      "Episode: 204, Score: -32.0, Avg reward: -44.42\n",
      "Episode: 205, Score: -22.0, Avg reward: -44.18\n",
      "Episode: 206, Score: -44.0, Avg reward: -44.20\n",
      "Episode: 207, Score: -46.0, Avg reward: -44.18\n",
      "Episode: 208, Score: -40.0, Avg reward: -44.24\n",
      "Episode: 209, Score: -38.0, Avg reward: -44.14\n",
      "Episode: 210, Score: -42.0, Avg reward: -44.16\n",
      "Episode: 211, Score: -46.0, Avg reward: -44.14\n",
      "Episode: 212, Score: -8.0, Avg reward: -43.80\n",
      "Episode: 213, Score: -42.0, Avg reward: -43.78\n",
      "Episode: 214, Score: -48.0, Avg reward: -43.82\n",
      "Episode: 215, Score: -46.0, Avg reward: -43.86\n",
      "Episode: 216, Score: -48.0, Avg reward: -43.88\n",
      "Episode: 217, Score: -32.0, Avg reward: -43.74\n",
      "Episode: 218, Score: -48.0, Avg reward: -43.76\n",
      "Episode: 219, Score: -46.0, Avg reward: -43.80\n",
      "Episode: 220, Score: -46.0, Avg reward: -43.80\n",
      "Episode: 221, Score: -42.0, Avg reward: -43.80\n",
      "Episode: 222, Score: -48.0, Avg reward: -43.86\n",
      "Episode: 223, Score: -46.0, Avg reward: -43.88\n",
      "Episode: 224, Score: -46.0, Avg reward: -43.86\n",
      "Episode: 225, Score: -48.0, Avg reward: -43.88\n",
      "Episode: 226, Score: -46.0, Avg reward: -43.86\n",
      "Episode: 227, Score: -44.0, Avg reward: -43.82\n",
      "Episode: 228, Score: -46.0, Avg reward: -43.80\n",
      "Episode: 229, Score: -46.0, Avg reward: -43.82\n",
      "Episode: 230, Score: -46.0, Avg reward: -43.82\n",
      "Episode: 231, Score: -44.0, Avg reward: -43.84\n",
      "Episode: 232, Score: -46.0, Avg reward: -43.84\n",
      "Episode: 233, Score: -44.0, Avg reward: -43.82\n",
      "Episode: 234, Score: -46.0, Avg reward: -43.84\n",
      "Episode: 235, Score: -48.0, Avg reward: -43.90\n",
      "Episode: 236, Score: -48.0, Avg reward: -43.94\n",
      "Episode: 237, Score: -42.0, Avg reward: -43.92\n",
      "Episode: 238, Score: -48.0, Avg reward: -43.92\n",
      "Episode: 239, Score: -48.0, Avg reward: -43.94\n",
      "Episode: 240, Score: -48.0, Avg reward: -43.94\n",
      "Episode: 241, Score: -48.0, Avg reward: -43.94\n",
      "Episode: 242, Score: -48.0, Avg reward: -43.98\n",
      "Episode: 243, Score: -48.0, Avg reward: -44.04\n",
      "Episode: 244, Score: -44.0, Avg reward: -44.00\n",
      "Episode: 245, Score: -44.0, Avg reward: -44.00\n",
      "Episode: 246, Score: -46.0, Avg reward: -44.02\n",
      "Episode: 247, Score: -46.0, Avg reward: -44.04\n",
      "Episode: 248, Score: -44.0, Avg reward: -44.04\n",
      "Episode: 249, Score: -40.0, Avg reward: -44.06\n",
      "Episode: 250, Score: -36.0, Avg reward: -43.94\n",
      "Episode: 251, Score: -34.0, Avg reward: -43.80\n",
      "Episode: 252, Score: -46.0, Avg reward: -43.78\n",
      "Episode: 253, Score: -48.0, Avg reward: -43.80\n",
      "Episode: 254, Score: -40.0, Avg reward: -43.78\n",
      "Episode: 255, Score: -46.0, Avg reward: -43.78\n",
      "Episode: 256, Score: -44.0, Avg reward: -43.80\n",
      "Episode: 257, Score: -48.0, Avg reward: -43.86\n",
      "Episode: 258, Score: -46.0, Avg reward: -43.84\n",
      "Episode: 259, Score: -48.0, Avg reward: -43.84\n",
      "Episode: 260, Score: -42.0, Avg reward: -43.78\n",
      "Episode: 261, Score: -42.0, Avg reward: -43.72\n",
      "Episode: 262, Score: -40.0, Avg reward: -43.64\n",
      "Episode: 263, Score: -48.0, Avg reward: -43.66\n",
      "Episode: 264, Score: -42.0, Avg reward: -43.60\n",
      "Episode: 265, Score: -42.0, Avg reward: -43.58\n",
      "Episode: 266, Score: -44.0, Avg reward: -43.58\n",
      "Episode: 267, Score: -44.0, Avg reward: -43.60\n",
      "Episode: 268, Score: -44.0, Avg reward: -43.56\n",
      "Episode: 269, Score: -46.0, Avg reward: -43.98\n",
      "Episode: 270, Score: -48.0, Avg reward: -43.98\n",
      "Episode: 271, Score: -46.0, Avg reward: -44.02\n",
      "Episode: 272, Score: -40.0, Avg reward: -43.94\n",
      "Episode: 273, Score: -42.0, Avg reward: -43.90\n",
      "Episode: 274, Score: -42.0, Avg reward: -43.84\n",
      "Episode: 275, Score: -46.0, Avg reward: -43.82\n",
      "Episode: 276, Score: -46.0, Avg reward: -43.82\n",
      "Episode: 277, Score: -42.0, Avg reward: -43.76\n",
      "Episode: 278, Score: -42.0, Avg reward: -43.74\n",
      "Episode: 279, Score: -48.0, Avg reward: -43.78\n",
      "Episode: 280, Score: -42.0, Avg reward: -43.74\n",
      "Episode: 281, Score: -44.0, Avg reward: -43.72\n",
      "Episode: 282, Score: -48.0, Avg reward: -43.74\n",
      "Episode: 283, Score: -48.0, Avg reward: -43.74\n",
      "Episode: 284, Score: -46.0, Avg reward: -43.78\n",
      "Episode: 285, Score: -44.0, Avg reward: -44.08\n",
      "Episode: 286, Score: -44.0, Avg reward: -44.06\n",
      "Episode: 287, Score: -46.0, Avg reward: -44.04\n",
      "Episode: 288, Score: -44.0, Avg reward: -44.00\n",
      "Episode: 289, Score: -46.0, Avg reward: -44.00\n",
      "Episode: 290, Score: -48.0, Avg reward: -44.02\n",
      "Episode: 291, Score: -44.0, Avg reward: -44.04\n",
      "Episode: 292, Score: -44.0, Avg reward: -44.02\n",
      "Episode: 293, Score: -46.0, Avg reward: -44.00\n",
      "Episode: 294, Score: -44.0, Avg reward: -43.98\n",
      "Episode: 295, Score: -46.0, Avg reward: -44.00\n",
      "Episode: 296, Score: -48.0, Avg reward: -44.02\n",
      "Episode: 297, Score: -44.0, Avg reward: -43.98\n",
      "Episode: 298, Score: -46.0, Avg reward: -43.98\n",
      "Episode: 299, Score: -42.0, Avg reward: -43.94\n",
      "Episode: 300, Score: -40.0, Avg reward: -43.90\n",
      "Episode: 301, Score: -46.0, Avg reward: -43.98\n",
      "Episode: 302, Score: -44.0, Avg reward: -43.94\n",
      "Episode: 303, Score: -44.0, Avg reward: -43.92\n",
      "Episode: 304, Score: -44.0, Avg reward: -44.04\n",
      "Episode: 305, Score: -48.0, Avg reward: -44.30\n",
      "Episode: 306, Score: -46.0, Avg reward: -44.32\n",
      "Episode: 307, Score: -48.0, Avg reward: -44.34\n",
      "Episode: 308, Score: -46.0, Avg reward: -44.40\n",
      "Episode: 309, Score: -46.0, Avg reward: -44.48\n",
      "Episode: 310, Score: -46.0, Avg reward: -44.52\n",
      "Episode: 311, Score: -36.0, Avg reward: -44.42\n",
      "Episode: 312, Score: -44.0, Avg reward: -44.78\n",
      "Episode: 313, Score: -46.0, Avg reward: -44.82\n",
      "Episode: 314, Score: -48.0, Avg reward: -44.82\n",
      "Episode: 315, Score: -48.0, Avg reward: -44.84\n",
      "Episode: 316, Score: -48.0, Avg reward: -44.84\n",
      "Episode: 317, Score: -48.0, Avg reward: -45.00\n",
      "Episode: 318, Score: -48.0, Avg reward: -45.00\n",
      "Episode: 319, Score: -44.0, Avg reward: -44.98\n",
      "Episode: 320, Score: -48.0, Avg reward: -45.00\n",
      "Episode: 321, Score: -46.0, Avg reward: -45.04\n",
      "Episode: 322, Score: -44.0, Avg reward: -45.00\n",
      "Episode: 323, Score: -48.0, Avg reward: -45.02\n",
      "Episode: 324, Score: -46.0, Avg reward: -45.02\n",
      "Episode: 325, Score: -48.0, Avg reward: -45.02\n",
      "Episode: 326, Score: -44.0, Avg reward: -45.00\n",
      "Episode: 327, Score: -46.0, Avg reward: -45.02\n",
      "Episode: 328, Score: -38.0, Avg reward: -44.94\n",
      "Episode: 329, Score: -48.0, Avg reward: -44.96\n",
      "Episode: 330, Score: -46.0, Avg reward: -44.96\n",
      "Episode: 331, Score: -46.0, Avg reward: -44.98\n",
      "Episode: 332, Score: -48.0, Avg reward: -45.00\n",
      "Episode: 333, Score: -46.0, Avg reward: -45.02\n",
      "Episode: 334, Score: -48.0, Avg reward: -45.04\n",
      "Episode: 335, Score: -46.0, Avg reward: -45.02\n",
      "Episode: 336, Score: -48.0, Avg reward: -45.02\n",
      "Episode: 337, Score: -46.0, Avg reward: -45.06\n",
      "Episode: 338, Score: -48.0, Avg reward: -45.06\n",
      "Episode: 339, Score: -44.0, Avg reward: -45.02\n",
      "Episode: 340, Score: -44.0, Avg reward: -44.98\n",
      "Episode: 341, Score: -48.0, Avg reward: -44.98\n",
      "Episode: 342, Score: -44.0, Avg reward: -44.94\n",
      "Episode: 343, Score: -42.0, Avg reward: -44.88\n",
      "Episode: 344, Score: -44.0, Avg reward: -44.88\n",
      "Episode: 345, Score: -48.0, Avg reward: -44.92\n",
      "Episode: 346, Score: -38.0, Avg reward: -44.84\n",
      "Episode: 347, Score: -42.0, Avg reward: -44.80\n",
      "Episode: 348, Score: -46.0, Avg reward: -44.82\n",
      "Episode: 349, Score: -46.0, Avg reward: -44.88\n",
      "Episode: 350, Score: -44.0, Avg reward: -44.96\n",
      "Episode: 351, Score: -46.0, Avg reward: -45.08\n",
      "Episode: 352, Score: -34.0, Avg reward: -44.96\n",
      "Episode: 353, Score: -44.0, Avg reward: -44.92\n",
      "Episode: 354, Score: -44.0, Avg reward: -44.96\n",
      "Episode: 355, Score: -48.0, Avg reward: -44.98\n",
      "Episode: 356, Score: -46.0, Avg reward: -45.00\n",
      "Episode: 357, Score: -48.0, Avg reward: -45.00\n",
      "Episode: 358, Score: -28.0, Avg reward: -44.82\n",
      "Episode: 359, Score: -48.0, Avg reward: -44.82\n",
      "Episode: 360, Score: -44.0, Avg reward: -44.84\n",
      "Episode: 361, Score: -46.0, Avg reward: -44.88\n",
      "Episode: 362, Score: -42.0, Avg reward: -44.90\n",
      "Episode: 363, Score: -44.0, Avg reward: -44.86\n",
      "Episode: 364, Score: -48.0, Avg reward: -44.92\n",
      "Episode: 365, Score: -48.0, Avg reward: -44.98\n",
      "Episode: 366, Score: -48.0, Avg reward: -45.02\n",
      "Episode: 367, Score: -48.0, Avg reward: -45.06\n",
      "Episode: 368, Score: -46.0, Avg reward: -45.08\n",
      "Episode: 369, Score: -46.0, Avg reward: -45.08\n",
      "Episode: 370, Score: -42.0, Avg reward: -45.02\n",
      "Episode: 371, Score: -44.0, Avg reward: -45.00\n",
      "Episode: 372, Score: -46.0, Avg reward: -45.06\n",
      "Episode: 373, Score: -46.0, Avg reward: -45.10\n",
      "Episode: 374, Score: -42.0, Avg reward: -45.10\n",
      "Episode: 375, Score: -48.0, Avg reward: -45.12\n",
      "Episode: 376, Score: -48.0, Avg reward: -45.14\n",
      "Episode: 377, Score: -46.0, Avg reward: -45.18\n",
      "Episode: 378, Score: -44.0, Avg reward: -45.20\n",
      "Episode: 379, Score: -48.0, Avg reward: -45.20\n",
      "Episode: 380, Score: -30.0, Avg reward: -45.08\n",
      "Episode: 381, Score: -44.0, Avg reward: -45.08\n",
      "Episode: 382, Score: -44.0, Avg reward: -45.04\n",
      "Episode: 383, Score: -48.0, Avg reward: -45.04\n",
      "Episode: 384, Score: -48.0, Avg reward: -45.06\n",
      "Episode: 385, Score: -40.0, Avg reward: -45.02\n",
      "Episode: 386, Score: -46.0, Avg reward: -45.04\n",
      "Episode: 387, Score: -48.0, Avg reward: -45.06\n",
      "Episode: 388, Score: -48.0, Avg reward: -45.10\n",
      "Episode: 389, Score: -46.0, Avg reward: -45.10\n",
      "Episode: 390, Score: -42.0, Avg reward: -45.04\n",
      "Episode: 391, Score: -46.0, Avg reward: -45.06\n",
      "Episode: 392, Score: -48.0, Avg reward: -45.10\n",
      "Episode: 393, Score: -44.0, Avg reward: -45.08\n",
      "Episode: 394, Score: -46.0, Avg reward: -45.10\n",
      "Episode: 395, Score: -48.0, Avg reward: -45.12\n",
      "Episode: 396, Score: -46.0, Avg reward: -45.10\n",
      "Episode: 397, Score: -48.0, Avg reward: -45.14\n",
      "Episode: 398, Score: -44.0, Avg reward: -45.12\n",
      "Episode: 399, Score: -48.0, Avg reward: -45.18\n",
      "Episode: 400, Score: -44.0, Avg reward: -45.22\n",
      "Episode: 401, Score: -32.0, Avg reward: -45.08\n",
      "Episode: 402, Score: -48.0, Avg reward: -45.12\n",
      "Episode: 403, Score: -46.0, Avg reward: -45.14\n",
      "Episode: 404, Score: -46.0, Avg reward: -45.16\n",
      "Episode: 405, Score: -48.0, Avg reward: -45.16\n",
      "Episode: 406, Score: -48.0, Avg reward: -45.18\n",
      "Episode: 407, Score: -48.0, Avg reward: -45.18\n",
      "Episode: 408, Score: -46.0, Avg reward: -45.18\n",
      "Episode: 409, Score: -42.0, Avg reward: -45.14\n",
      "Episode: 410, Score: -24.0, Avg reward: -44.92\n",
      "Episode: 411, Score: -46.0, Avg reward: -45.02\n",
      "Episode: 412, Score: -48.0, Avg reward: -45.06\n",
      "Episode: 413, Score: -38.0, Avg reward: -44.98\n",
      "Episode: 414, Score: -46.0, Avg reward: -44.96\n",
      "Episode: 415, Score: -20.0, Avg reward: -44.68\n",
      "Episode: 416, Score: -48.0, Avg reward: -44.68\n",
      "Episode: 417, Score: -48.0, Avg reward: -44.68\n",
      "Episode: 418, Score: -48.0, Avg reward: -44.68\n",
      "Episode: 419, Score: -42.0, Avg reward: -44.66\n",
      "Episode: 420, Score: -42.0, Avg reward: -44.60\n",
      "Episode: 421, Score: -16.0, Avg reward: -44.30\n",
      "Episode: 422, Score: -48.0, Avg reward: -44.34\n",
      "Episode: 423, Score: -44.0, Avg reward: -44.30\n",
      "Episode: 424, Score: -46.0, Avg reward: -44.30\n",
      "Episode: 425, Score: -34.0, Avg reward: -44.16\n",
      "Episode: 426, Score: -48.0, Avg reward: -44.20\n",
      "Episode: 427, Score: -44.0, Avg reward: -44.18\n",
      "Episode: 428, Score: -48.0, Avg reward: -44.28\n",
      "Episode: 429, Score: -48.0, Avg reward: -44.28\n",
      "Episode: 430, Score: -48.0, Avg reward: -44.30\n",
      "Episode: 431, Score: -44.0, Avg reward: -44.28\n",
      "Episode: 432, Score: -44.0, Avg reward: -44.24\n",
      "Episode: 433, Score: -46.0, Avg reward: -44.24\n",
      "Episode: 434, Score: -48.0, Avg reward: -44.24\n",
      "Episode: 435, Score: -46.0, Avg reward: -44.24\n",
      "Episode: 436, Score: -14.0, Avg reward: -43.90\n",
      "Episode: 437, Score: -44.0, Avg reward: -43.88\n",
      "Episode: 438, Score: -48.0, Avg reward: -43.88\n",
      "Episode: 439, Score: -46.0, Avg reward: -43.90\n",
      "Episode: 440, Score: -48.0, Avg reward: -43.94\n",
      "Episode: 441, Score: -46.0, Avg reward: -43.92\n",
      "Episode: 442, Score: -48.0, Avg reward: -43.96\n",
      "Episode: 443, Score: -48.0, Avg reward: -44.02\n",
      "Episode: 444, Score: -46.0, Avg reward: -44.04\n",
      "Episode: 445, Score: -44.0, Avg reward: -44.00\n",
      "Episode: 446, Score: -48.0, Avg reward: -44.10\n",
      "Episode: 447, Score: -48.0, Avg reward: -44.16\n",
      "Episode: 448, Score: -38.0, Avg reward: -44.08\n",
      "Episode: 449, Score: -48.0, Avg reward: -44.10\n",
      "Episode: 450, Score: -44.0, Avg reward: -44.10\n",
      "Episode: 451, Score: -48.0, Avg reward: -44.12\n",
      "Episode: 452, Score: -40.0, Avg reward: -44.18\n",
      "Episode: 453, Score: -44.0, Avg reward: -44.18\n",
      "Episode: 454, Score: -44.0, Avg reward: -44.18\n",
      "Episode: 455, Score: -42.0, Avg reward: -44.12\n",
      "Episode: 456, Score: -40.0, Avg reward: -44.06\n",
      "Episode: 457, Score: -44.0, Avg reward: -44.02\n",
      "Episode: 458, Score: -32.0, Avg reward: -44.06\n",
      "Episode: 459, Score: -36.0, Avg reward: -43.94\n",
      "Episode: 460, Score: -48.0, Avg reward: -43.98\n",
      "Episode: 461, Score: -44.0, Avg reward: -43.96\n",
      "Episode: 462, Score: -44.0, Avg reward: -43.98\n",
      "Episode: 463, Score: -46.0, Avg reward: -44.00\n",
      "Episode: 464, Score: -46.0, Avg reward: -43.98\n",
      "Episode: 465, Score: -44.0, Avg reward: -43.94\n",
      "Episode: 466, Score: -42.0, Avg reward: -43.88\n",
      "Episode: 467, Score: -44.0, Avg reward: -43.84\n",
      "Episode: 468, Score: -42.0, Avg reward: -43.80\n",
      "Episode: 469, Score: -48.0, Avg reward: -43.82\n",
      "Episode: 470, Score: -44.0, Avg reward: -43.84\n",
      "Episode: 471, Score: -46.0, Avg reward: -43.86\n",
      "Episode: 472, Score: -48.0, Avg reward: -43.88\n",
      "Episode: 473, Score: -48.0, Avg reward: -43.90\n",
      "Episode: 474, Score: -44.0, Avg reward: -43.92\n",
      "Episode: 475, Score: -40.0, Avg reward: -43.84\n",
      "Episode: 476, Score: -44.0, Avg reward: -43.80\n",
      "Episode: 477, Score: -44.0, Avg reward: -43.78\n",
      "Episode: 478, Score: -44.0, Avg reward: -43.78\n",
      "Episode: 479, Score: -48.0, Avg reward: -43.78\n",
      "Episode: 480, Score: -42.0, Avg reward: -43.90\n",
      "Episode: 481, Score: -44.0, Avg reward: -43.90\n",
      "Episode: 482, Score: -48.0, Avg reward: -43.94\n",
      "Episode: 483, Score: -48.0, Avg reward: -43.94\n",
      "Episode: 484, Score: -48.0, Avg reward: -43.94\n",
      "Episode: 485, Score: -46.0, Avg reward: -44.00\n",
      "Episode: 486, Score: -48.0, Avg reward: -44.02\n",
      "Episode: 487, Score: -46.0, Avg reward: -44.00\n",
      "Episode: 488, Score: -44.0, Avg reward: -43.96\n",
      "Episode: 489, Score: -48.0, Avg reward: -43.98\n",
      "Episode: 490, Score: -46.0, Avg reward: -44.02\n",
      "Episode: 491, Score: -40.0, Avg reward: -43.96\n",
      "Episode: 492, Score: -8.0, Avg reward: -43.56\n",
      "Episode: 493, Score: -44.0, Avg reward: -43.56\n",
      "Episode: 494, Score: -46.0, Avg reward: -43.56\n",
      "Episode: 495, Score: -34.0, Avg reward: -43.42\n",
      "Episode: 496, Score: -42.0, Avg reward: -43.38\n",
      "Episode: 497, Score: -44.0, Avg reward: -43.34\n",
      "Episode: 498, Score: -48.0, Avg reward: -43.38\n",
      "Episode: 499, Score: -42.0, Avg reward: -43.32\n",
      "Episode: 500, Score: -48.0, Avg reward: -43.36\n",
      "Episode: 501, Score: -46.0, Avg reward: -43.50\n",
      "Episode: 502, Score: -44.0, Avg reward: -43.46\n",
      "Episode: 503, Score: -40.0, Avg reward: -43.40\n",
      "Episode: 504, Score: -46.0, Avg reward: -43.40\n",
      "Episode: 505, Score: -46.0, Avg reward: -43.38\n",
      "Episode: 506, Score: -44.0, Avg reward: -43.34\n",
      "Episode: 507, Score: -46.0, Avg reward: -43.32\n",
      "Episode: 508, Score: -40.0, Avg reward: -43.26\n",
      "Episode: 509, Score: -48.0, Avg reward: -43.32\n",
      "Episode: 510, Score: -48.0, Avg reward: -43.56\n",
      "Episode: 511, Score: -32.0, Avg reward: -43.42\n",
      "Episode: 512, Score: -48.0, Avg reward: -43.42\n",
      "Episode: 513, Score: -46.0, Avg reward: -43.50\n",
      "Episode: 514, Score: -46.0, Avg reward: -43.50\n",
      "Episode: 515, Score: -46.0, Avg reward: -43.76\n",
      "Episode: 516, Score: -44.0, Avg reward: -43.72\n",
      "Episode: 517, Score: -48.0, Avg reward: -43.72\n",
      "Episode: 518, Score: -46.0, Avg reward: -43.70\n",
      "Episode: 519, Score: -46.0, Avg reward: -43.74\n",
      "Episode: 520, Score: -46.0, Avg reward: -43.78\n",
      "Episode: 521, Score: -48.0, Avg reward: -44.10\n",
      "Episode: 522, Score: -46.0, Avg reward: -44.08\n",
      "Episode: 523, Score: -48.0, Avg reward: -44.12\n",
      "Episode: 524, Score: -44.0, Avg reward: -44.10\n",
      "Episode: 525, Score: -48.0, Avg reward: -44.24\n",
      "Episode: 526, Score: -42.0, Avg reward: -44.18\n",
      "Episode: 527, Score: -48.0, Avg reward: -44.22\n",
      "Episode: 528, Score: -48.0, Avg reward: -44.22\n",
      "Episode: 529, Score: -42.0, Avg reward: -44.16\n",
      "Episode: 530, Score: -44.0, Avg reward: -44.12\n",
      "Episode: 531, Score: -42.0, Avg reward: -44.10\n",
      "Episode: 532, Score: -48.0, Avg reward: -44.14\n",
      "Episode: 533, Score: -46.0, Avg reward: -44.14\n",
      "Episode: 534, Score: -48.0, Avg reward: -44.14\n",
      "Episode: 535, Score: -48.0, Avg reward: -44.16\n",
      "Episode: 536, Score: -48.0, Avg reward: -44.50\n",
      "Episode: 537, Score: -48.0, Avg reward: -44.54\n",
      "Episode: 538, Score: -42.0, Avg reward: -44.48\n",
      "Episode: 539, Score: -28.0, Avg reward: -44.30\n",
      "Episode: 540, Score: -46.0, Avg reward: -44.28\n",
      "Episode: 541, Score: -40.0, Avg reward: -44.22\n",
      "Episode: 542, Score: -44.0, Avg reward: -44.18\n",
      "Episode: 543, Score: -48.0, Avg reward: -44.18\n",
      "Episode: 544, Score: -42.0, Avg reward: -44.14\n",
      "Episode: 545, Score: -48.0, Avg reward: -44.18\n",
      "Episode: 546, Score: -48.0, Avg reward: -44.18\n",
      "Episode: 547, Score: -46.0, Avg reward: -44.16\n",
      "Episode: 548, Score: -44.0, Avg reward: -44.22\n",
      "Episode: 549, Score: -48.0, Avg reward: -44.22\n",
      "Episode: 550, Score: -44.0, Avg reward: -44.22\n",
      "Episode: 551, Score: -46.0, Avg reward: -44.20\n",
      "Episode: 552, Score: -48.0, Avg reward: -44.28\n",
      "Episode: 553, Score: -46.0, Avg reward: -44.30\n",
      "Episode: 554, Score: -48.0, Avg reward: -44.34\n",
      "Episode: 555, Score: -48.0, Avg reward: -44.40\n",
      "Episode: 556, Score: -46.0, Avg reward: -44.46\n",
      "Episode: 557, Score: -42.0, Avg reward: -44.44\n",
      "Episode: 558, Score: -48.0, Avg reward: -44.60\n",
      "Episode: 559, Score: -38.0, Avg reward: -44.62\n",
      "Episode: 560, Score: -42.0, Avg reward: -44.56\n",
      "Episode: 561, Score: -44.0, Avg reward: -44.56\n",
      "Episode: 562, Score: -48.0, Avg reward: -44.60\n",
      "Episode: 563, Score: -46.0, Avg reward: -44.60\n",
      "Episode: 564, Score: -46.0, Avg reward: -44.60\n",
      "Episode: 565, Score: -44.0, Avg reward: -44.60\n",
      "Episode: 566, Score: -48.0, Avg reward: -44.66\n",
      "Episode: 567, Score: -44.0, Avg reward: -44.66\n",
      "Episode: 568, Score: -38.0, Avg reward: -44.62\n",
      "Episode: 569, Score: -46.0, Avg reward: -44.60\n",
      "Episode: 570, Score: -42.0, Avg reward: -44.58\n",
      "Episode: 571, Score: -44.0, Avg reward: -44.56\n",
      "Episode: 572, Score: -2.0, Avg reward: -44.10\n",
      "Episode: 573, Score: -46.0, Avg reward: -44.08\n",
      "Episode: 574, Score: -42.0, Avg reward: -44.06\n",
      "Episode: 575, Score: -46.0, Avg reward: -44.12\n",
      "Episode: 576, Score: -16.0, Avg reward: -43.84\n",
      "Episode: 577, Score: -48.0, Avg reward: -43.88\n",
      "Episode: 578, Score: -46.0, Avg reward: -43.90\n",
      "Episode: 579, Score: -46.0, Avg reward: -43.88\n",
      "Episode: 580, Score: -46.0, Avg reward: -43.92\n",
      "Episode: 581, Score: -42.0, Avg reward: -43.90\n",
      "Episode: 582, Score: -46.0, Avg reward: -43.88\n",
      "Episode: 583, Score: -46.0, Avg reward: -43.86\n",
      "Episode: 584, Score: -42.0, Avg reward: -43.80\n",
      "Episode: 585, Score: -42.0, Avg reward: -43.76\n",
      "Episode: 586, Score: -46.0, Avg reward: -43.74\n",
      "Episode: 587, Score: -44.0, Avg reward: -43.72\n",
      "Episode: 588, Score: -36.0, Avg reward: -43.64\n",
      "Episode: 589, Score: -46.0, Avg reward: -43.62\n",
      "Episode: 590, Score: -44.0, Avg reward: -43.60\n",
      "Episode: 591, Score: 0.0, Avg reward: -43.20\n",
      "Episode: 592, Score: -48.0, Avg reward: -43.60\n",
      "Episode: 593, Score: -44.0, Avg reward: -43.60\n",
      "Episode: 594, Score: -48.0, Avg reward: -43.62\n",
      "Episode: 595, Score: -44.0, Avg reward: -43.72\n",
      "Episode: 596, Score: -48.0, Avg reward: -43.78\n",
      "Episode: 597, Score: -44.0, Avg reward: -43.78\n",
      "Episode: 598, Score: -46.0, Avg reward: -43.76\n",
      "Episode: 599, Score: -46.0, Avg reward: -43.80\n",
      "Episode: 600, Score: -46.0, Avg reward: -43.78\n",
      "Episode: 601, Score: -46.0, Avg reward: -43.78\n",
      "Episode: 602, Score: -48.0, Avg reward: -43.82\n",
      "Episode: 603, Score: -12.0, Avg reward: -43.54\n",
      "Episode: 604, Score: -46.0, Avg reward: -43.54\n",
      "Episode: 605, Score: -42.0, Avg reward: -43.50\n",
      "Episode: 606, Score: -48.0, Avg reward: -43.54\n",
      "Episode: 607, Score: -42.0, Avg reward: -43.50\n",
      "Episode: 608, Score: -44.0, Avg reward: -43.54\n",
      "Episode: 609, Score: -48.0, Avg reward: -43.54\n",
      "Episode: 610, Score: -38.0, Avg reward: -43.44\n",
      "Episode: 611, Score: -40.0, Avg reward: -43.52\n",
      "Episode: 612, Score: -46.0, Avg reward: -43.50\n",
      "Episode: 613, Score: -38.0, Avg reward: -43.42\n",
      "Episode: 614, Score: -46.0, Avg reward: -43.42\n",
      "Episode: 615, Score: -48.0, Avg reward: -43.44\n",
      "Episode: 616, Score: -48.0, Avg reward: -43.48\n",
      "Episode: 617, Score: -46.0, Avg reward: -43.46\n",
      "Episode: 618, Score: -48.0, Avg reward: -43.48\n",
      "Episode: 619, Score: -44.0, Avg reward: -43.46\n",
      "Episode: 620, Score: -48.0, Avg reward: -43.48\n",
      "Episode: 621, Score: -44.0, Avg reward: -43.44\n",
      "Episode: 622, Score: -48.0, Avg reward: -43.46\n",
      "Episode: 623, Score: -48.0, Avg reward: -43.46\n",
      "Episode: 624, Score: -48.0, Avg reward: -43.50\n",
      "Episode: 625, Score: -48.0, Avg reward: -43.50\n",
      "Episode: 626, Score: -46.0, Avg reward: -43.54\n",
      "Episode: 627, Score: -46.0, Avg reward: -43.52\n",
      "Episode: 628, Score: -48.0, Avg reward: -43.52\n",
      "Episode: 629, Score: -34.0, Avg reward: -43.44\n",
      "Episode: 630, Score: -48.0, Avg reward: -43.48\n",
      "Episode: 631, Score: -42.0, Avg reward: -43.48\n",
      "Episode: 632, Score: -44.0, Avg reward: -43.44\n",
      "Episode: 633, Score: -46.0, Avg reward: -43.44\n",
      "Episode: 634, Score: -18.0, Avg reward: -43.14\n",
      "Episode: 635, Score: -42.0, Avg reward: -43.08\n",
      "Episode: 636, Score: -46.0, Avg reward: -43.06\n",
      "Episode: 637, Score: -48.0, Avg reward: -43.06\n",
      "Episode: 638, Score: -40.0, Avg reward: -43.04\n",
      "Episode: 639, Score: -16.0, Avg reward: -42.92\n",
      "Episode: 640, Score: -40.0, Avg reward: -42.86\n",
      "Episode: 641, Score: -44.0, Avg reward: -42.90\n",
      "Episode: 642, Score: -48.0, Avg reward: -42.94\n",
      "Episode: 643, Score: -44.0, Avg reward: -42.90\n",
      "Episode: 644, Score: -12.0, Avg reward: -42.60\n",
      "Episode: 645, Score: -44.0, Avg reward: -42.56\n",
      "Episode: 646, Score: -46.0, Avg reward: -42.54\n",
      "Episode: 647, Score: -42.0, Avg reward: -42.50\n",
      "Episode: 648, Score: -10.0, Avg reward: -42.16\n",
      "Episode: 649, Score: -46.0, Avg reward: -42.14\n",
      "Episode: 650, Score: -48.0, Avg reward: -42.18\n",
      "Episode: 651, Score: -46.0, Avg reward: -42.18\n",
      "Episode: 652, Score: -48.0, Avg reward: -42.18\n",
      "Episode: 653, Score: -44.0, Avg reward: -42.16\n",
      "Episode: 654, Score: -8.0, Avg reward: -41.76\n",
      "Episode: 655, Score: -46.0, Avg reward: -41.74\n",
      "Episode: 656, Score: -46.0, Avg reward: -41.74\n",
      "Episode: 657, Score: -44.0, Avg reward: -41.76\n",
      "Episode: 658, Score: -48.0, Avg reward: -41.76\n",
      "Episode: 659, Score: -44.0, Avg reward: -41.82\n",
      "Episode: 660, Score: -34.0, Avg reward: -41.74\n",
      "Episode: 661, Score: -48.0, Avg reward: -41.78\n",
      "Episode: 662, Score: -48.0, Avg reward: -41.78\n",
      "Episode: 663, Score: -44.0, Avg reward: -41.76\n",
      "Episode: 664, Score: -48.0, Avg reward: -41.78\n",
      "Episode: 665, Score: -48.0, Avg reward: -41.82\n",
      "Episode: 666, Score: -46.0, Avg reward: -41.80\n",
      "Episode: 667, Score: -42.0, Avg reward: -41.78\n",
      "Episode: 668, Score: -44.0, Avg reward: -41.84\n",
      "Episode: 669, Score: -42.0, Avg reward: -41.80\n",
      "Episode: 670, Score: -46.0, Avg reward: -41.84\n",
      "Episode: 671, Score: -42.0, Avg reward: -41.82\n",
      "Episode: 672, Score: -46.0, Avg reward: -42.26\n",
      "Episode: 673, Score: -42.0, Avg reward: -42.22\n",
      "Episode: 674, Score: -48.0, Avg reward: -42.28\n",
      "Episode: 675, Score: -46.0, Avg reward: -42.28\n",
      "Episode: 676, Score: -44.0, Avg reward: -42.56\n",
      "Episode: 677, Score: -46.0, Avg reward: -42.54\n",
      "Episode: 678, Score: -44.0, Avg reward: -42.52\n",
      "Episode: 679, Score: -42.0, Avg reward: -42.48\n",
      "Episode: 680, Score: -34.0, Avg reward: -42.36\n",
      "Episode: 681, Score: -44.0, Avg reward: -42.38\n",
      "Episode: 682, Score: -48.0, Avg reward: -42.40\n",
      "Episode: 683, Score: -36.0, Avg reward: -42.30\n",
      "Episode: 684, Score: -44.0, Avg reward: -42.32\n",
      "Episode: 685, Score: -48.0, Avg reward: -42.38\n",
      "Episode: 686, Score: -40.0, Avg reward: -42.32\n",
      "Episode: 687, Score: -48.0, Avg reward: -42.36\n",
      "Episode: 688, Score: -46.0, Avg reward: -42.46\n",
      "Episode: 689, Score: -40.0, Avg reward: -42.40\n",
      "Episode: 690, Score: -46.0, Avg reward: -42.42\n",
      "Episode: 691, Score: -48.0, Avg reward: -42.90\n",
      "Episode: 692, Score: -40.0, Avg reward: -42.82\n",
      "Episode: 693, Score: -44.0, Avg reward: -42.82\n",
      "Episode: 694, Score: -46.0, Avg reward: -42.80\n",
      "Episode: 695, Score: -44.0, Avg reward: -42.80\n",
      "Episode: 696, Score: -46.0, Avg reward: -42.78\n",
      "Episode: 697, Score: -48.0, Avg reward: -42.82\n",
      "Episode: 698, Score: -38.0, Avg reward: -42.74\n",
      "Episode: 699, Score: -48.0, Avg reward: -42.76\n",
      "Episode: 700, Score: -42.0, Avg reward: -42.72\n",
      "Episode: 701, Score: -46.0, Avg reward: -42.72\n",
      "Episode: 702, Score: -46.0, Avg reward: -42.70\n",
      "Episode: 703, Score: -48.0, Avg reward: -43.06\n",
      "Episode: 704, Score: -48.0, Avg reward: -43.08\n",
      "Episode: 705, Score: -48.0, Avg reward: -43.14\n",
      "Episode: 706, Score: -46.0, Avg reward: -43.12\n",
      "Episode: 707, Score: 6.0, Avg reward: -42.64\n",
      "Episode: 708, Score: -44.0, Avg reward: -42.64\n",
      "Episode: 709, Score: -46.0, Avg reward: -42.62\n",
      "Episode: 710, Score: -46.0, Avg reward: -42.70\n",
      "Episode: 711, Score: -44.0, Avg reward: -42.74\n",
      "Episode: 712, Score: -26.0, Avg reward: -42.54\n",
      "Episode: 713, Score: -44.0, Avg reward: -42.60\n",
      "Episode: 714, Score: -46.0, Avg reward: -42.60\n",
      "Episode: 715, Score: -44.0, Avg reward: -42.56\n",
      "Episode: 716, Score: -46.0, Avg reward: -42.54\n",
      "Episode: 717, Score: -46.0, Avg reward: -42.54\n",
      "Episode: 718, Score: -48.0, Avg reward: -42.54\n",
      "Episode: 719, Score: -48.0, Avg reward: -42.58\n",
      "Episode: 720, Score: -46.0, Avg reward: -42.56\n",
      "Episode: 721, Score: -44.0, Avg reward: -42.56\n",
      "Episode: 722, Score: -48.0, Avg reward: -42.56\n",
      "Episode: 723, Score: -46.0, Avg reward: -42.54\n",
      "Episode: 724, Score: -46.0, Avg reward: -42.52\n",
      "Episode: 725, Score: -46.0, Avg reward: -42.50\n",
      "Episode: 726, Score: -2.0, Avg reward: -42.06\n",
      "Episode: 727, Score: -42.0, Avg reward: -42.02\n",
      "Episode: 728, Score: -42.0, Avg reward: -41.96\n",
      "Episode: 729, Score: -46.0, Avg reward: -42.08\n",
      "Episode: 730, Score: -44.0, Avg reward: -42.04\n",
      "Episode: 731, Score: -44.0, Avg reward: -42.06\n",
      "Episode: 732, Score: -42.0, Avg reward: -42.04\n",
      "Episode: 733, Score: -48.0, Avg reward: -42.06\n",
      "Episode: 734, Score: -48.0, Avg reward: -42.36\n",
      "Episode: 735, Score: -44.0, Avg reward: -42.38\n",
      "Episode: 736, Score: -48.0, Avg reward: -42.40\n",
      "Episode: 737, Score: -48.0, Avg reward: -42.40\n",
      "Episode: 738, Score: -42.0, Avg reward: -42.42\n",
      "Episode: 739, Score: -42.0, Avg reward: -42.68\n",
      "Episode: 740, Score: -48.0, Avg reward: -42.76\n",
      "Episode: 741, Score: -48.0, Avg reward: -42.80\n",
      "Episode: 742, Score: -42.0, Avg reward: -42.74\n",
      "Episode: 743, Score: -48.0, Avg reward: -42.78\n",
      "Episode: 744, Score: -48.0, Avg reward: -43.14\n",
      "Episode: 745, Score: -44.0, Avg reward: -43.14\n",
      "Episode: 746, Score: -48.0, Avg reward: -43.16\n",
      "Episode: 747, Score: -46.0, Avg reward: -43.20\n",
      "Episode: 748, Score: -36.0, Avg reward: -43.46\n",
      "Episode: 749, Score: -48.0, Avg reward: -43.48\n",
      "Episode: 750, Score: -44.0, Avg reward: -43.44\n",
      "Episode: 751, Score: -42.0, Avg reward: -43.40\n",
      "Episode: 752, Score: -42.0, Avg reward: -43.34\n",
      "Episode: 753, Score: -44.0, Avg reward: -43.34\n",
      "Episode: 754, Score: -40.0, Avg reward: -43.66\n",
      "Episode: 755, Score: -44.0, Avg reward: -43.64\n",
      "Episode: 756, Score: -38.0, Avg reward: -43.56\n",
      "Episode: 757, Score: -10.0, Avg reward: -43.22\n",
      "Episode: 758, Score: -42.0, Avg reward: -43.16\n",
      "Episode: 759, Score: -12.0, Avg reward: -42.84\n",
      "Episode: 760, Score: -48.0, Avg reward: -42.98\n",
      "Episode: 761, Score: -48.0, Avg reward: -42.98\n",
      "Episode: 762, Score: -46.0, Avg reward: -42.96\n",
      "Episode: 763, Score: -44.0, Avg reward: -42.96\n",
      "Episode: 764, Score: -44.0, Avg reward: -42.92\n",
      "Episode: 765, Score: -10.0, Avg reward: -42.54\n",
      "Episode: 766, Score: -44.0, Avg reward: -42.52\n",
      "Episode: 767, Score: -46.0, Avg reward: -42.56\n",
      "Episode: 768, Score: -40.0, Avg reward: -42.52\n",
      "Episode: 769, Score: -46.0, Avg reward: -42.56\n",
      "Episode: 770, Score: -10.0, Avg reward: -42.20\n",
      "Episode: 771, Score: -36.0, Avg reward: -42.14\n",
      "Episode: 772, Score: -38.0, Avg reward: -42.06\n",
      "Episode: 773, Score: -42.0, Avg reward: -42.06\n",
      "Episode: 774, Score: -48.0, Avg reward: -42.06\n",
      "Episode: 775, Score: -32.0, Avg reward: -41.92\n",
      "Episode: 776, Score: -46.0, Avg reward: -41.94\n",
      "Episode: 777, Score: -48.0, Avg reward: -41.96\n",
      "Episode: 778, Score: -30.0, Avg reward: -41.82\n",
      "Episode: 779, Score: -28.0, Avg reward: -41.68\n",
      "Episode: 780, Score: -36.0, Avg reward: -41.70\n",
      "Episode: 781, Score: -46.0, Avg reward: -41.72\n",
      "Episode: 782, Score: -46.0, Avg reward: -41.70\n",
      "Episode: 783, Score: -46.0, Avg reward: -41.80\n",
      "Episode: 784, Score: -46.0, Avg reward: -41.82\n",
      "Episode: 785, Score: -28.0, Avg reward: -41.62\n",
      "Episode: 786, Score: -46.0, Avg reward: -41.68\n",
      "Episode: 787, Score: -48.0, Avg reward: -41.68\n",
      "Episode: 788, Score: 20.0, Avg reward: -41.02\n",
      "Episode: 789, Score: -46.0, Avg reward: -41.08\n",
      "Episode: 790, Score: -32.0, Avg reward: -40.94\n",
      "Episode: 791, Score: -48.0, Avg reward: -40.94\n",
      "Episode: 792, Score: -44.0, Avg reward: -40.98\n",
      "Episode: 793, Score: -44.0, Avg reward: -40.98\n",
      "Episode: 794, Score: -40.0, Avg reward: -40.92\n",
      "Episode: 795, Score: -40.0, Avg reward: -40.88\n",
      "Episode: 796, Score: -38.0, Avg reward: -40.80\n",
      "Episode: 797, Score: -44.0, Avg reward: -40.76\n",
      "Episode: 798, Score: -46.0, Avg reward: -40.84\n",
      "Episode: 799, Score: -46.0, Avg reward: -40.82\n",
      "Episode: 800, Score: -46.0, Avg reward: -40.86\n",
      "Episode: 801, Score: -42.0, Avg reward: -40.82\n",
      "Episode: 802, Score: -48.0, Avg reward: -40.84\n",
      "Episode: 803, Score: -20.0, Avg reward: -40.56\n",
      "Episode: 804, Score: -46.0, Avg reward: -40.54\n",
      "Episode: 805, Score: -48.0, Avg reward: -40.54\n",
      "Episode: 806, Score: -46.0, Avg reward: -40.54\n",
      "Episode: 807, Score: -42.0, Avg reward: -41.02\n",
      "Episode: 808, Score: -46.0, Avg reward: -41.04\n",
      "Episode: 809, Score: -42.0, Avg reward: -41.00\n",
      "Episode: 810, Score: -46.0, Avg reward: -41.00\n",
      "Episode: 811, Score: -44.0, Avg reward: -41.00\n",
      "Episode: 812, Score: -44.0, Avg reward: -41.18\n",
      "Episode: 813, Score: -48.0, Avg reward: -41.22\n",
      "Episode: 814, Score: -48.0, Avg reward: -41.24\n",
      "Episode: 815, Score: -46.0, Avg reward: -41.26\n",
      "Episode: 816, Score: -46.0, Avg reward: -41.26\n",
      "Episode: 817, Score: -46.0, Avg reward: -41.26\n",
      "Episode: 818, Score: -46.0, Avg reward: -41.24\n",
      "Episode: 819, Score: -44.0, Avg reward: -41.20\n",
      "Episode: 820, Score: -48.0, Avg reward: -41.22\n",
      "Episode: 821, Score: -48.0, Avg reward: -41.26\n",
      "Episode: 822, Score: -40.0, Avg reward: -41.18\n",
      "Episode: 823, Score: -46.0, Avg reward: -41.18\n",
      "Episode: 824, Score: -44.0, Avg reward: -41.16\n",
      "Episode: 825, Score: -32.0, Avg reward: -41.02\n",
      "Episode: 826, Score: -48.0, Avg reward: -41.48\n",
      "Episode: 827, Score: -28.0, Avg reward: -41.34\n",
      "Episode: 828, Score: -44.0, Avg reward: -41.36\n",
      "Episode: 829, Score: -40.0, Avg reward: -41.30\n",
      "Episode: 830, Score: -44.0, Avg reward: -41.30\n",
      "Episode: 831, Score: -38.0, Avg reward: -41.24\n",
      "Episode: 832, Score: -42.0, Avg reward: -41.24\n",
      "Episode: 833, Score: -40.0, Avg reward: -41.16\n",
      "Episode: 834, Score: -12.0, Avg reward: -40.80\n",
      "Episode: 835, Score: -40.0, Avg reward: -40.76\n",
      "Episode: 836, Score: -44.0, Avg reward: -40.72\n",
      "Episode: 837, Score: -44.0, Avg reward: -40.68\n",
      "Episode: 838, Score: -38.0, Avg reward: -40.64\n",
      "Episode: 839, Score: -44.0, Avg reward: -40.66\n",
      "Episode: 840, Score: -42.0, Avg reward: -40.60\n",
      "Episode: 841, Score: -48.0, Avg reward: -40.60\n",
      "Episode: 842, Score: -32.0, Avg reward: -40.50\n",
      "Episode: 843, Score: -18.0, Avg reward: -40.20\n",
      "Episode: 844, Score: -34.0, Avg reward: -40.06\n",
      "Episode: 845, Score: -42.0, Avg reward: -40.04\n",
      "Episode: 846, Score: -38.0, Avg reward: -39.94\n",
      "Episode: 847, Score: -42.0, Avg reward: -39.90\n",
      "Episode: 848, Score: -40.0, Avg reward: -39.94\n",
      "Episode: 849, Score: -46.0, Avg reward: -39.92\n",
      "Episode: 850, Score: -44.0, Avg reward: -39.92\n",
      "Episode: 851, Score: -40.0, Avg reward: -39.90\n",
      "Episode: 852, Score: -38.0, Avg reward: -39.86\n",
      "Episode: 853, Score: -46.0, Avg reward: -39.88\n",
      "Episode: 854, Score: -38.0, Avg reward: -39.86\n",
      "Episode: 855, Score: -18.0, Avg reward: -39.60\n",
      "Episode: 856, Score: -40.0, Avg reward: -39.62\n",
      "Episode: 857, Score: -46.0, Avg reward: -39.98\n",
      "Episode: 858, Score: -38.0, Avg reward: -39.94\n",
      "Episode: 859, Score: -46.0, Avg reward: -40.28\n",
      "Episode: 860, Score: -48.0, Avg reward: -40.28\n",
      "Episode: 861, Score: -46.0, Avg reward: -40.26\n",
      "Episode: 862, Score: -44.0, Avg reward: -40.24\n",
      "Episode: 863, Score: -48.0, Avg reward: -40.28\n",
      "Episode: 864, Score: -36.0, Avg reward: -40.20\n",
      "Episode: 865, Score: -48.0, Avg reward: -40.58\n",
      "Episode: 866, Score: -46.0, Avg reward: -40.60\n",
      "Episode: 867, Score: -48.0, Avg reward: -40.62\n",
      "Episode: 868, Score: -48.0, Avg reward: -40.70\n",
      "Episode: 869, Score: -28.0, Avg reward: -40.52\n",
      "Episode: 870, Score: -42.0, Avg reward: -40.84\n",
      "Episode: 871, Score: -36.0, Avg reward: -40.84\n",
      "Episode: 872, Score: -40.0, Avg reward: -40.86\n",
      "Episode: 873, Score: -42.0, Avg reward: -40.86\n",
      "Episode: 874, Score: -48.0, Avg reward: -40.86\n",
      "Episode: 875, Score: -10.0, Avg reward: -40.64\n",
      "Episode: 876, Score: -38.0, Avg reward: -40.56\n",
      "Episode: 877, Score: -46.0, Avg reward: -40.54\n",
      "Episode: 878, Score: -46.0, Avg reward: -40.70\n",
      "Episode: 879, Score: -36.0, Avg reward: -40.78\n",
      "Episode: 880, Score: -44.0, Avg reward: -40.86\n",
      "Episode: 881, Score: -44.0, Avg reward: -40.84\n",
      "Episode: 882, Score: -38.0, Avg reward: -40.76\n",
      "Episode: 883, Score: -46.0, Avg reward: -40.76\n",
      "Episode: 884, Score: -40.0, Avg reward: -40.70\n",
      "Episode: 885, Score: -48.0, Avg reward: -40.90\n",
      "Episode: 886, Score: -46.0, Avg reward: -40.90\n",
      "Episode: 887, Score: -44.0, Avg reward: -40.86\n",
      "Episode: 888, Score: 28.0, Avg reward: -40.78\n",
      "Episode: 889, Score: -44.0, Avg reward: -40.76\n",
      "Episode: 890, Score: -44.0, Avg reward: -40.88\n",
      "Episode: 891, Score: -32.0, Avg reward: -40.72\n",
      "Episode: 892, Score: -40.0, Avg reward: -40.68\n",
      "Episode: 893, Score: -44.0, Avg reward: -40.68\n",
      "Episode: 894, Score: -24.0, Avg reward: -40.52\n",
      "Episode: 895, Score: -32.0, Avg reward: -40.44\n",
      "Episode: 896, Score: -38.0, Avg reward: -40.44\n",
      "Episode: 897, Score: -42.0, Avg reward: -40.42\n",
      "Episode: 898, Score: -42.0, Avg reward: -40.38\n",
      "Episode: 899, Score: -40.0, Avg reward: -40.32\n",
      "Episode: 900, Score: -46.0, Avg reward: -40.32\n",
      "Episode: 901, Score: -46.0, Avg reward: -40.36\n",
      "Episode: 902, Score: -20.0, Avg reward: -40.08\n",
      "Episode: 903, Score: -42.0, Avg reward: -40.30\n",
      "Episode: 904, Score: -46.0, Avg reward: -40.30\n",
      "Episode: 905, Score: -42.0, Avg reward: -40.24\n",
      "Episode: 906, Score: -42.0, Avg reward: -40.20\n",
      "Episode: 907, Score: -48.0, Avg reward: -40.26\n",
      "Episode: 908, Score: -38.0, Avg reward: -40.18\n",
      "Episode: 909, Score: -46.0, Avg reward: -40.22\n",
      "Episode: 910, Score: -40.0, Avg reward: -40.16\n",
      "Episode: 911, Score: -46.0, Avg reward: -40.18\n",
      "Episode: 912, Score: -40.0, Avg reward: -40.14\n",
      "Episode: 913, Score: -46.0, Avg reward: -40.12\n",
      "Episode: 914, Score: -48.0, Avg reward: -40.12\n",
      "Episode: 915, Score: -36.0, Avg reward: -40.02\n",
      "Episode: 916, Score: -46.0, Avg reward: -40.02\n",
      "Episode: 917, Score: -46.0, Avg reward: -40.02\n",
      "Episode: 918, Score: -30.0, Avg reward: -39.86\n",
      "Episode: 919, Score: -40.0, Avg reward: -39.82\n",
      "Episode: 920, Score: -48.0, Avg reward: -39.82\n",
      "Episode: 921, Score: -46.0, Avg reward: -39.80\n",
      "Episode: 922, Score: -36.0, Avg reward: -39.76\n",
      "Episode: 923, Score: -28.0, Avg reward: -39.58\n",
      "Episode: 924, Score: -26.0, Avg reward: -39.40\n",
      "Episode: 925, Score: -36.0, Avg reward: -39.44\n",
      "Episode: 926, Score: -46.0, Avg reward: -39.42\n",
      "Episode: 927, Score: -48.0, Avg reward: -39.62\n",
      "Episode: 928, Score: -46.0, Avg reward: -39.64\n",
      "Episode: 929, Score: -30.0, Avg reward: -39.54\n",
      "Episode: 930, Score: -40.0, Avg reward: -39.50\n",
      "Episode: 931, Score: -46.0, Avg reward: -39.58\n",
      "Episode: 932, Score: -46.0, Avg reward: -39.62\n",
      "Episode: 933, Score: -42.0, Avg reward: -39.64\n",
      "Episode: 934, Score: -44.0, Avg reward: -39.96\n",
      "Episode: 935, Score: -48.0, Avg reward: -40.04\n",
      "Episode: 936, Score: -42.0, Avg reward: -40.02\n",
      "Episode: 937, Score: -32.0, Avg reward: -39.90\n",
      "Episode: 938, Score: -24.0, Avg reward: -39.76\n",
      "Episode: 939, Score: 38.0, Avg reward: -38.94\n",
      "Episode: 940, Score: -42.0, Avg reward: -38.94\n",
      "Episode: 941, Score: -40.0, Avg reward: -38.86\n",
      "Episode: 942, Score: -38.0, Avg reward: -38.92\n",
      "Episode: 943, Score: -48.0, Avg reward: -39.22\n",
      "Episode: 944, Score: -46.0, Avg reward: -39.34\n",
      "Episode: 945, Score: -32.0, Avg reward: -39.24\n",
      "Episode: 946, Score: -32.0, Avg reward: -39.18\n",
      "Episode: 947, Score: -48.0, Avg reward: -39.24\n",
      "Episode: 948, Score: -40.0, Avg reward: -39.24\n",
      "Episode: 949, Score: -32.0, Avg reward: -39.10\n",
      "Episode: 950, Score: 18.0, Avg reward: -38.48\n",
      "Episode: 951, Score: -44.0, Avg reward: -38.52\n",
      "Episode: 952, Score: -24.0, Avg reward: -38.38\n",
      "Episode: 953, Score: -42.0, Avg reward: -38.34\n",
      "Episode: 954, Score: -46.0, Avg reward: -38.42\n",
      "Episode: 955, Score: -42.0, Avg reward: -38.66\n",
      "Episode: 956, Score: -40.0, Avg reward: -38.66\n",
      "Episode: 957, Score: -42.0, Avg reward: -38.62\n",
      "Episode: 958, Score: -30.0, Avg reward: -38.54\n",
      "Episode: 959, Score: -34.0, Avg reward: -38.42\n",
      "Episode: 960, Score: 4.0, Avg reward: -37.90\n",
      "Episode: 961, Score: -30.0, Avg reward: -37.74\n",
      "Episode: 962, Score: -42.0, Avg reward: -37.72\n",
      "Episode: 963, Score: -36.0, Avg reward: -37.60\n",
      "Episode: 964, Score: -22.0, Avg reward: -37.46\n",
      "Episode: 965, Score: -12.0, Avg reward: -37.10\n",
      "Episode: 966, Score: -48.0, Avg reward: -37.12\n",
      "Episode: 967, Score: -48.0, Avg reward: -37.12\n",
      "Episode: 968, Score: -18.0, Avg reward: -36.82\n",
      "Episode: 969, Score: -4.0, Avg reward: -36.58\n",
      "Episode: 970, Score: -38.0, Avg reward: -36.54\n",
      "Episode: 971, Score: -46.0, Avg reward: -36.64\n",
      "Episode: 972, Score: -42.0, Avg reward: -36.66\n",
      "Episode: 973, Score: -48.0, Avg reward: -36.72\n",
      "Episode: 974, Score: -44.0, Avg reward: -36.68\n",
      "Episode: 975, Score: -48.0, Avg reward: -37.06\n",
      "Episode: 976, Score: -30.0, Avg reward: -36.98\n",
      "Episode: 977, Score: -34.0, Avg reward: -36.86\n",
      "Episode: 978, Score: -46.0, Avg reward: -36.86\n",
      "Episode: 979, Score: -40.0, Avg reward: -36.90\n",
      "Episode: 980, Score: -34.0, Avg reward: -36.80\n",
      "Episode: 981, Score: -44.0, Avg reward: -36.80\n",
      "Episode: 982, Score: -48.0, Avg reward: -36.90\n",
      "Episode: 983, Score: -44.0, Avg reward: -36.88\n",
      "Episode: 984, Score: -42.0, Avg reward: -36.90\n",
      "Episode: 985, Score: -46.0, Avg reward: -36.88\n",
      "Episode: 986, Score: 10.0, Avg reward: -36.32\n",
      "Episode: 987, Score: -18.0, Avg reward: -36.06\n",
      "Episode: 988, Score: -40.0, Avg reward: -36.74\n",
      "Episode: 989, Score: 0.0, Avg reward: -36.30\n",
      "Episode: 990, Score: -44.0, Avg reward: -36.30\n",
      "Episode: 991, Score: -18.0, Avg reward: -36.16\n",
      "Episode: 992, Score: -44.0, Avg reward: -36.20\n",
      "Episode: 993, Score: -42.0, Avg reward: -36.18\n",
      "Episode: 994, Score: -46.0, Avg reward: -36.40\n",
      "Episode: 995, Score: -44.0, Avg reward: -36.52\n",
      "Episode: 996, Score: -30.0, Avg reward: -36.44\n",
      "Episode: 997, Score: -46.0, Avg reward: -36.48\n",
      "Episode: 998, Score: -34.0, Avg reward: -36.40\n",
      "Episode: 999, Score: -46.0, Avg reward: -36.46\n",
      "Episode: 1000, Score: -38.0, Avg reward: -36.38\n",
      "Episode: 1001, Score: -6.0, Avg reward: -35.98\n",
      "Episode: 1002, Score: -20.0, Avg reward: -35.98\n",
      "Episode: 1003, Score: -48.0, Avg reward: -36.04\n",
      "Episode: 1004, Score: -44.0, Avg reward: -36.02\n",
      "Episode: 1005, Score: -38.0, Avg reward: -35.98\n",
      "Episode: 1006, Score: -40.0, Avg reward: -35.96\n",
      "Episode: 1007, Score: -48.0, Avg reward: -35.96\n",
      "Episode: 1008, Score: -42.0, Avg reward: -36.00\n",
      "Episode: 1009, Score: -44.0, Avg reward: -35.98\n",
      "Episode: 1010, Score: -38.0, Avg reward: -35.96\n",
      "Episode: 1011, Score: -20.0, Avg reward: -35.70\n",
      "Episode: 1012, Score: -34.0, Avg reward: -35.64\n",
      "Episode: 1013, Score: -30.0, Avg reward: -35.48\n",
      "Episode: 1014, Score: -48.0, Avg reward: -35.48\n",
      "Episode: 1015, Score: -48.0, Avg reward: -35.60\n",
      "Episode: 1016, Score: -42.0, Avg reward: -35.56\n",
      "Episode: 1017, Score: -38.0, Avg reward: -35.48\n",
      "Episode: 1018, Score: -42.0, Avg reward: -35.60\n",
      "Episode: 1019, Score: -30.0, Avg reward: -35.50\n",
      "Episode: 1020, Score: -16.0, Avg reward: -35.18\n",
      "Episode: 1021, Score: -44.0, Avg reward: -35.16\n",
      "Episode: 1022, Score: -24.0, Avg reward: -35.04\n",
      "Episode: 1023, Score: -32.0, Avg reward: -35.08\n",
      "Episode: 1024, Score: -32.0, Avg reward: -35.14\n",
      "Episode: 1025, Score: -32.0, Avg reward: -35.10\n",
      "Episode: 1026, Score: -40.0, Avg reward: -35.04\n",
      "Episode: 1027, Score: -14.0, Avg reward: -34.70\n",
      "Episode: 1028, Score: -44.0, Avg reward: -34.68\n",
      "Episode: 1029, Score: -44.0, Avg reward: -34.82\n",
      "Episode: 1030, Score: -34.0, Avg reward: -34.76\n",
      "Episode: 1031, Score: -4.0, Avg reward: -34.34\n",
      "Episode: 1032, Score: -44.0, Avg reward: -34.32\n",
      "Episode: 1033, Score: -46.0, Avg reward: -34.36\n",
      "Episode: 1034, Score: -48.0, Avg reward: -34.40\n",
      "Episode: 1035, Score: -40.0, Avg reward: -34.32\n",
      "Episode: 1036, Score: -32.0, Avg reward: -34.22\n",
      "Episode: 1037, Score: -42.0, Avg reward: -34.32\n",
      "Episode: 1038, Score: -40.0, Avg reward: -34.48\n",
      "Episode: 1039, Score: -46.0, Avg reward: -35.32\n",
      "Episode: 1040, Score: -48.0, Avg reward: -35.38\n",
      "Episode: 1041, Score: -28.0, Avg reward: -35.26\n",
      "Episode: 1042, Score: -46.0, Avg reward: -35.34\n",
      "Episode: 1043, Score: -48.0, Avg reward: -35.34\n",
      "Episode: 1044, Score: -34.0, Avg reward: -35.22\n",
      "Episode: 1045, Score: -38.0, Avg reward: -35.28\n",
      "Episode: 1046, Score: -48.0, Avg reward: -35.44\n",
      "Episode: 1047, Score: -46.0, Avg reward: -35.42\n",
      "Episode: 1048, Score: -48.0, Avg reward: -35.50\n",
      "Episode: 1049, Score: -40.0, Avg reward: -35.58\n",
      "Episode: 1050, Score: -36.0, Avg reward: -36.12\n",
      "Episode: 1051, Score: -38.0, Avg reward: -36.06\n",
      "Episode: 1052, Score: -28.0, Avg reward: -36.10\n",
      "Episode: 1053, Score: -28.0, Avg reward: -35.96\n",
      "Episode: 1054, Score: 22.0, Avg reward: -35.28\n",
      "Episode: 1055, Score: -26.0, Avg reward: -35.12\n",
      "Episode: 1056, Score: -46.0, Avg reward: -35.18\n",
      "Episode: 1057, Score: -46.0, Avg reward: -35.22\n",
      "Episode: 1058, Score: -32.0, Avg reward: -35.24\n",
      "Episode: 1059, Score: -46.0, Avg reward: -35.36\n",
      "Episode: 1060, Score: -22.0, Avg reward: -35.62\n",
      "Episode: 1061, Score: -28.0, Avg reward: -35.60\n",
      "Episode: 1062, Score: -36.0, Avg reward: -35.54\n",
      "Episode: 1063, Score: -32.0, Avg reward: -35.50\n",
      "Episode: 1064, Score: -12.0, Avg reward: -35.40\n",
      "Episode: 1065, Score: -42.0, Avg reward: -35.70\n",
      "Episode: 1066, Score: -14.0, Avg reward: -35.36\n",
      "Episode: 1067, Score: 2.0, Avg reward: -34.86\n",
      "Episode: 1068, Score: -32.0, Avg reward: -35.00\n",
      "Episode: 1069, Score: -36.0, Avg reward: -35.32\n",
      "Episode: 1070, Score: -40.0, Avg reward: -35.34\n",
      "Episode: 1071, Score: -48.0, Avg reward: -35.36\n",
      "Episode: 1072, Score: -48.0, Avg reward: -35.42\n",
      "Episode: 1073, Score: -22.0, Avg reward: -35.16\n",
      "Episode: 1074, Score: -20.0, Avg reward: -34.92\n",
      "Episode: 1075, Score: -28.0, Avg reward: -34.72\n",
      "Episode: 1076, Score: -22.0, Avg reward: -34.64\n",
      "Episode: 1077, Score: -48.0, Avg reward: -34.78\n",
      "Episode: 1078, Score: -38.0, Avg reward: -34.70\n",
      "Episode: 1079, Score: -34.0, Avg reward: -34.64\n",
      "Episode: 1080, Score: -4.0, Avg reward: -34.34\n",
      "Episode: 1081, Score: -44.0, Avg reward: -34.34\n",
      "Episode: 1082, Score: -4.0, Avg reward: -33.90\n",
      "Episode: 1083, Score: -28.0, Avg reward: -33.74\n",
      "Episode: 1084, Score: -16.0, Avg reward: -33.48\n",
      "Episode: 1085, Score: -42.0, Avg reward: -33.44\n",
      "Episode: 1086, Score: -22.0, Avg reward: -33.76\n",
      "Episode: 1087, Score: -24.0, Avg reward: -33.82\n",
      "Episode: 1088, Score: -46.0, Avg reward: -33.88\n",
      "Episode: 1089, Score: -32.0, Avg reward: -34.20\n",
      "Episode: 1090, Score: -32.0, Avg reward: -34.08\n",
      "Episode: 1091, Score: -46.0, Avg reward: -34.36\n",
      "Episode: 1092, Score: -48.0, Avg reward: -34.40\n",
      "Episode: 1093, Score: 2.0, Avg reward: -33.96\n",
      "Episode: 1094, Score: -34.0, Avg reward: -33.84\n",
      "Episode: 1095, Score: -12.0, Avg reward: -33.52\n",
      "Episode: 1096, Score: 6.0, Avg reward: -33.16\n",
      "Episode: 1097, Score: -38.0, Avg reward: -33.08\n",
      "Episode: 1098, Score: -38.0, Avg reward: -33.12\n",
      "Episode: 1099, Score: 16.0, Avg reward: -32.50\n",
      "Episode: 1100, Score: -44.0, Avg reward: -32.56\n",
      "Episode: 1101, Score: -20.0, Avg reward: -32.70\n",
      "Episode: 1102, Score: -30.0, Avg reward: -32.80\n",
      "Episode: 1103, Score: -44.0, Avg reward: -32.76\n",
      "Episode: 1104, Score: -34.0, Avg reward: -32.66\n",
      "Episode: 1105, Score: -36.0, Avg reward: -32.64\n",
      "Episode: 1106, Score: -46.0, Avg reward: -32.70\n",
      "Episode: 1107, Score: -26.0, Avg reward: -32.48\n",
      "Episode: 1108, Score: -20.0, Avg reward: -32.26\n",
      "Episode: 1109, Score: -26.0, Avg reward: -32.08\n",
      "Episode: 1110, Score: 6.0, Avg reward: -31.64\n",
      "Episode: 1111, Score: -46.0, Avg reward: -31.90\n",
      "Episode: 1112, Score: -32.0, Avg reward: -31.88\n",
      "Episode: 1113, Score: -44.0, Avg reward: -32.02\n",
      "Episode: 1114, Score: -26.0, Avg reward: -31.80\n",
      "Episode: 1115, Score: -40.0, Avg reward: -31.72\n",
      "Episode: 1116, Score: 20.0, Avg reward: -31.10\n",
      "Episode: 1117, Score: -36.0, Avg reward: -31.08\n",
      "Episode: 1118, Score: -42.0, Avg reward: -31.08\n",
      "Episode: 1119, Score: -46.0, Avg reward: -31.24\n",
      "Episode: 1120, Score: -46.0, Avg reward: -31.54\n",
      "Episode: 1121, Score: -34.0, Avg reward: -31.44\n",
      "Episode: 1122, Score: -42.0, Avg reward: -31.62\n",
      "Episode: 1123, Score: -36.0, Avg reward: -31.66\n",
      "Episode: 1124, Score: -22.0, Avg reward: -31.56\n",
      "Episode: 1125, Score: 4.0, Avg reward: -31.20\n",
      "Episode: 1126, Score: -8.0, Avg reward: -30.88\n",
      "Episode: 1127, Score: 6.0, Avg reward: -30.68\n",
      "Episode: 1128, Score: -44.0, Avg reward: -30.68\n",
      "Episode: 1129, Score: -34.0, Avg reward: -30.58\n",
      "Episode: 1130, Score: -40.0, Avg reward: -30.64\n",
      "Episode: 1131, Score: -14.0, Avg reward: -30.74\n",
      "Episode: 1132, Score: -8.0, Avg reward: -30.38\n",
      "Episode: 1133, Score: -34.0, Avg reward: -30.26\n",
      "Episode: 1134, Score: -24.0, Avg reward: -30.02\n",
      "Episode: 1135, Score: -8.0, Avg reward: -29.70\n",
      "Episode: 1136, Score: -20.0, Avg reward: -29.58\n",
      "Episode: 1137, Score: 34.0, Avg reward: -28.82\n",
      "Episode: 1138, Score: -44.0, Avg reward: -28.86\n",
      "Episode: 1139, Score: -40.0, Avg reward: -28.80\n",
      "Episode: 1140, Score: -30.0, Avg reward: -28.62\n",
      "Episode: 1141, Score: -36.0, Avg reward: -28.70\n",
      "Episode: 1142, Score: 0.0, Avg reward: -28.24\n",
      "Episode: 1143, Score: -22.0, Avg reward: -27.98\n",
      "Episode: 1144, Score: -16.0, Avg reward: -27.80\n",
      "Episode: 1145, Score: -38.0, Avg reward: -27.80\n",
      "Episode: 1146, Score: 8.0, Avg reward: -27.24\n",
      "Episode: 1147, Score: -30.0, Avg reward: -27.08\n",
      "Episode: 1148, Score: -28.0, Avg reward: -26.88\n",
      "Episode: 1149, Score: -18.0, Avg reward: -26.66\n",
      "Episode: 1150, Score: -36.0, Avg reward: -26.66\n",
      "Episode: 1151, Score: -16.0, Avg reward: -26.44\n",
      "Episode: 1152, Score: -34.0, Avg reward: -26.50\n",
      "Episode: 1153, Score: -18.0, Avg reward: -26.40\n",
      "Episode: 1154, Score: -44.0, Avg reward: -27.06\n",
      "Episode: 1155, Score: 10.0, Avg reward: -26.70\n",
      "Episode: 1156, Score: 16.0, Avg reward: -26.08\n",
      "Episode: 1157, Score: -30.0, Avg reward: -25.92\n",
      "Episode: 1158, Score: 14.0, Avg reward: -25.46\n",
      "Episode: 1159, Score: -46.0, Avg reward: -25.46\n",
      "Episode: 1160, Score: -16.0, Avg reward: -25.40\n",
      "Episode: 1161, Score: -18.0, Avg reward: -25.30\n",
      "Episode: 1162, Score: -4.0, Avg reward: -24.98\n",
      "Episode: 1163, Score: -30.0, Avg reward: -24.96\n",
      "Episode: 1164, Score: -38.0, Avg reward: -25.22\n",
      "Episode: 1165, Score: 4.0, Avg reward: -24.76\n",
      "Episode: 1166, Score: -26.0, Avg reward: -24.88\n",
      "Episode: 1167, Score: -48.0, Avg reward: -25.38\n",
      "Episode: 1168, Score: -16.0, Avg reward: -25.22\n",
      "Episode: 1169, Score: -8.0, Avg reward: -24.94\n",
      "Episode: 1170, Score: 10.0, Avg reward: -24.44\n",
      "Episode: 1171, Score: -26.0, Avg reward: -24.22\n",
      "Episode: 1172, Score: -24.0, Avg reward: -23.98\n",
      "Episode: 1173, Score: 28.0, Avg reward: -23.48\n",
      "Episode: 1174, Score: -20.0, Avg reward: -23.48\n",
      "Episode: 1175, Score: -10.0, Avg reward: -23.30\n",
      "Episode: 1176, Score: -36.0, Avg reward: -23.44\n",
      "Episode: 1177, Score: -10.0, Avg reward: -23.06\n",
      "Episode: 1178, Score: -14.0, Avg reward: -22.82\n",
      "Episode: 1179, Score: -8.0, Avg reward: -22.56\n",
      "Episode: 1180, Score: -4.0, Avg reward: -22.56\n",
      "Episode: 1181, Score: -14.0, Avg reward: -22.26\n",
      "Episode: 1182, Score: -42.0, Avg reward: -22.64\n",
      "Episode: 1183, Score: -4.0, Avg reward: -22.40\n",
      "Episode: 1184, Score: 14.0, Avg reward: -22.10\n",
      "Episode: 1185, Score: 2.0, Avg reward: -21.66\n",
      "Episode: 1186, Score: -16.0, Avg reward: -21.60\n",
      "Episode: 1187, Score: 0.0, Avg reward: -21.36\n",
      "Episode: 1188, Score: -18.0, Avg reward: -21.08\n",
      "Episode: 1189, Score: -10.0, Avg reward: -20.86\n",
      "Episode: 1190, Score: 2.0, Avg reward: -20.52\n",
      "Episode: 1191, Score: -42.0, Avg reward: -20.48\n",
      "Episode: 1192, Score: -12.0, Avg reward: -20.12\n",
      "Episode: 1193, Score: 32.0, Avg reward: -19.82\n",
      "Episode: 1194, Score: 18.0, Avg reward: -19.30\n",
      "Episode: 1195, Score: -12.0, Avg reward: -19.30\n",
      "Episode: 1196, Score: -36.0, Avg reward: -19.72\n",
      "Episode: 1197, Score: -40.0, Avg reward: -19.74\n",
      "Episode: 1198, Score: -2.0, Avg reward: -19.38\n",
      "Episode: 1199, Score: -32.0, Avg reward: -19.86\n",
      "Episode: 1200, Score: -26.0, Avg reward: -19.68\n",
      "Episode: 1201, Score: -12.0, Avg reward: -19.60\n",
      "Episode: 1202, Score: -10.0, Avg reward: -19.40\n",
      "Episode: 1203, Score: -42.0, Avg reward: -19.38\n",
      "Episode: 1204, Score: -28.0, Avg reward: -19.32\n",
      "Episode: 1205, Score: -16.0, Avg reward: -19.12\n",
      "Episode: 1206, Score: 4.0, Avg reward: -18.62\n",
      "Episode: 1207, Score: 4.0, Avg reward: -18.32\n",
      "Episode: 1208, Score: -30.0, Avg reward: -18.42\n",
      "Episode: 1209, Score: -8.0, Avg reward: -18.24\n",
      "Episode: 1210, Score: 8.0, Avg reward: -18.22\n",
      "Episode: 1211, Score: -6.0, Avg reward: -17.82\n",
      "Episode: 1212, Score: 10.0, Avg reward: -17.40\n",
      "Episode: 1213, Score: -36.0, Avg reward: -17.32\n",
      "Episode: 1214, Score: -4.0, Avg reward: -17.10\n",
      "Episode: 1215, Score: 8.0, Avg reward: -16.62\n",
      "Episode: 1216, Score: 20.0, Avg reward: -16.62\n",
      "Episode: 1217, Score: -10.0, Avg reward: -16.36\n",
      "Episode: 1218, Score: -34.0, Avg reward: -16.28\n",
      "Episode: 1219, Score: -6.0, Avg reward: -15.88\n",
      "Episode: 1220, Score: -34.0, Avg reward: -15.76\n",
      "Episode: 1221, Score: -4.0, Avg reward: -15.46\n",
      "Episode: 1222, Score: -8.0, Avg reward: -15.12\n",
      "Episode: 1223, Score: -14.0, Avg reward: -14.90\n",
      "Episode: 1224, Score: -34.0, Avg reward: -15.02\n",
      "Episode: 1225, Score: -36.0, Avg reward: -15.42\n",
      "Episode: 1226, Score: 2.0, Avg reward: -15.32\n",
      "Episode: 1227, Score: 20.0, Avg reward: -15.18\n",
      "Episode: 1228, Score: -46.0, Avg reward: -15.20\n",
      "Episode: 1229, Score: -30.0, Avg reward: -15.16\n",
      "Episode: 1230, Score: 26.0, Avg reward: -14.50\n",
      "Episode: 1231, Score: 16.0, Avg reward: -14.20\n",
      "Episode: 1232, Score: -44.0, Avg reward: -14.56\n",
      "Episode: 1233, Score: -10.0, Avg reward: -14.32\n",
      "Episode: 1234, Score: -8.0, Avg reward: -14.16\n",
      "Episode: 1235, Score: -12.0, Avg reward: -14.20\n",
      "Episode: 1236, Score: -22.0, Avg reward: -14.22\n",
      "Episode: 1237, Score: -8.0, Avg reward: -14.64\n",
      "Episode: 1238, Score: -10.0, Avg reward: -14.30\n",
      "Episode: 1239, Score: -20.0, Avg reward: -14.10\n",
      "Episode: 1240, Score: -4.0, Avg reward: -13.84\n",
      "Episode: 1241, Score: 8.0, Avg reward: -13.40\n",
      "Episode: 1242, Score: 16.0, Avg reward: -13.24\n",
      "Episode: 1243, Score: 12.0, Avg reward: -12.90\n",
      "Episode: 1244, Score: -44.0, Avg reward: -13.18\n",
      "Episode: 1245, Score: 10.0, Avg reward: -12.70\n",
      "Episode: 1246, Score: 6.0, Avg reward: -12.72\n",
      "Episode: 1247, Score: 26.0, Avg reward: -12.16\n",
      "Episode: 1248, Score: -12.0, Avg reward: -12.00\n",
      "Episode: 1249, Score: -12.0, Avg reward: -11.94\n",
      "Episode: 1250, Score: -4.0, Avg reward: -11.62\n",
      "Episode: 1251, Score: -22.0, Avg reward: -11.68\n",
      "Episode: 1252, Score: -28.0, Avg reward: -11.62\n",
      "Episode: 1253, Score: -8.0, Avg reward: -11.52\n",
      "Episode: 1254, Score: -2.0, Avg reward: -11.10\n",
      "Episode: 1255, Score: -12.0, Avg reward: -11.32\n",
      "Episode: 1256, Score: -4.0, Avg reward: -11.52\n",
      "Episode: 1257, Score: -16.0, Avg reward: -11.38\n",
      "Episode: 1258, Score: 4.0, Avg reward: -11.48\n",
      "Episode: 1259, Score: 24.0, Avg reward: -10.78\n",
      "Episode: 1260, Score: 8.0, Avg reward: -10.54\n",
      "Episode: 1261, Score: 12.0, Avg reward: -10.24\n",
      "Episode: 1262, Score: -4.0, Avg reward: -10.24\n",
      "Episode: 1263, Score: -20.0, Avg reward: -10.14\n",
      "Episode: 1264, Score: 14.0, Avg reward: -9.62\n",
      "Episode: 1265, Score: -26.0, Avg reward: -9.92\n",
      "Episode: 1266, Score: -32.0, Avg reward: -9.98\n",
      "Episode: 1267, Score: -38.0, Avg reward: -9.88\n",
      "Episode: 1268, Score: 12.0, Avg reward: -9.60\n",
      "Episode: 1269, Score: -18.0, Avg reward: -9.70\n",
      "Episode: 1270, Score: 4.0, Avg reward: -9.76\n",
      "Episode: 1271, Score: -34.0, Avg reward: -9.84\n",
      "Episode: 1272, Score: -4.0, Avg reward: -9.64\n",
      "Episode: 1273, Score: -34.0, Avg reward: -10.26\n",
      "Episode: 1274, Score: 10.0, Avg reward: -9.96\n",
      "Episode: 1275, Score: 4.0, Avg reward: -9.82\n",
      "Episode: 1276, Score: 30.0, Avg reward: -9.16\n",
      "Episode: 1277, Score: 10.0, Avg reward: -8.96\n",
      "Episode: 1278, Score: -12.0, Avg reward: -8.94\n",
      "Episode: 1279, Score: 0.0, Avg reward: -8.86\n",
      "Episode: 1280, Score: -4.0, Avg reward: -8.86\n",
      "Episode: 1281, Score: 6.0, Avg reward: -8.66\n",
      "Episode: 1282, Score: -24.0, Avg reward: -8.48\n",
      "Episode: 1283, Score: -2.0, Avg reward: -8.46\n",
      "Episode: 1284, Score: -6.0, Avg reward: -8.66\n",
      "Episode: 1285, Score: 4.0, Avg reward: -8.64\n",
      "Episode: 1286, Score: -8.0, Avg reward: -8.56\n",
      "Episode: 1287, Score: 24.0, Avg reward: -8.32\n",
      "Episode: 1288, Score: 28.0, Avg reward: -7.86\n",
      "Episode: 1289, Score: -2.0, Avg reward: -7.78\n",
      "Episode: 1290, Score: -16.0, Avg reward: -7.96\n",
      "Episode: 1291, Score: -10.0, Avg reward: -7.64\n",
      "Episode: 1292, Score: -20.0, Avg reward: -7.72\n",
      "Episode: 1293, Score: -22.0, Avg reward: -8.26\n",
      "Episode: 1294, Score: 0.0, Avg reward: -8.44\n",
      "Episode: 1295, Score: 16.0, Avg reward: -8.16\n",
      "Episode: 1296, Score: 6.0, Avg reward: -7.74\n",
      "Episode: 1297, Score: 6.0, Avg reward: -7.28\n",
      "Episode: 1298, Score: 20.0, Avg reward: -7.06\n",
      "Episode: 1299, Score: -36.0, Avg reward: -7.10\n",
      "Episode: 1300, Score: 4.0, Avg reward: -6.80\n",
      "Episode: 1301, Score: -48.0, Avg reward: -7.16\n",
      "Episode: 1302, Score: 10.0, Avg reward: -6.96\n",
      "Episode: 1303, Score: 4.0, Avg reward: -6.50\n",
      "Episode: 1304, Score: -12.0, Avg reward: -6.34\n",
      "Episode: 1305, Score: 8.0, Avg reward: -6.10\n",
      "Episode: 1306, Score: 6.0, Avg reward: -6.08\n",
      "Episode: 1307, Score: 12.0, Avg reward: -6.00\n",
      "Episode: 1308, Score: 4.0, Avg reward: -5.66\n",
      "Episode: 1309, Score: -20.0, Avg reward: -5.78\n",
      "Episode: 1310, Score: -44.0, Avg reward: -6.30\n",
      "Episode: 1311, Score: 18.0, Avg reward: -6.06\n",
      "Episode: 1312, Score: 0.0, Avg reward: -6.16\n",
      "Episode: 1313, Score: -12.0, Avg reward: -5.92\n",
      "Episode: 1314, Score: 6.0, Avg reward: -5.82\n",
      "Episode: 1315, Score: 6.0, Avg reward: -5.84\n",
      "Episode: 1316, Score: 2.0, Avg reward: -6.02\n",
      "Episode: 1317, Score: -28.0, Avg reward: -6.20\n",
      "Episode: 1318, Score: 14.0, Avg reward: -5.72\n",
      "Episode: 1319, Score: -10.0, Avg reward: -5.76\n",
      "Episode: 1320, Score: 14.0, Avg reward: -5.28\n",
      "Episode: 1321, Score: -4.0, Avg reward: -5.28\n",
      "Episode: 1322, Score: 16.0, Avg reward: -5.04\n",
      "Episode: 1323, Score: -10.0, Avg reward: -5.00\n",
      "Episode: 1324, Score: 18.0, Avg reward: -4.48\n",
      "Episode: 1325, Score: -12.0, Avg reward: -4.24\n",
      "Episode: 1326, Score: 38.0, Avg reward: -3.88\n",
      "Episode: 1327, Score: -18.0, Avg reward: -4.26\n",
      "Episode: 1328, Score: -2.0, Avg reward: -3.82\n",
      "Episode: 1329, Score: 2.0, Avg reward: -3.50\n",
      "Episode: 1330, Score: 24.0, Avg reward: -3.52\n",
      "Episode: 1331, Score: 14.0, Avg reward: -3.54\n",
      "Episode: 1332, Score: 14.0, Avg reward: -2.96\n",
      "Episode: 1333, Score: 16.0, Avg reward: -2.70\n",
      "Episode: 1334, Score: 12.0, Avg reward: -2.50\n",
      "Episode: 1335, Score: 0.0, Avg reward: -2.38\n",
      "Episode: 1336, Score: 18.0, Avg reward: -1.98\n",
      "Episode: 1337, Score: 20.0, Avg reward: -1.70\n",
      "Episode: 1338, Score: 28.0, Avg reward: -1.32\n",
      "Episode: 1339, Score: -44.0, Avg reward: -1.56\n",
      "Episode: 1340, Score: 8.0, Avg reward: -1.44\n",
      "Episode: 1341, Score: -12.0, Avg reward: -1.64\n",
      "Episode: 1342, Score: 4.0, Avg reward: -1.76\n",
      "Episode: 1343, Score: 26.0, Avg reward: -1.62\n",
      "Episode: 1344, Score: -22.0, Avg reward: -1.40\n",
      "Episode: 1345, Score: 0.0, Avg reward: -1.50\n",
      "Episode: 1346, Score: 10.0, Avg reward: -1.46\n",
      "Episode: 1347, Score: 20.0, Avg reward: -1.52\n",
      "Episode: 1348, Score: 0.0, Avg reward: -1.40\n",
      "Episode: 1349, Score: 10.0, Avg reward: -1.18\n",
      "Episode: 1350, Score: -6.0, Avg reward: -1.20\n",
      "Episode: 1351, Score: 0.0, Avg reward: -0.98\n",
      "Episode: 1352, Score: -42.0, Avg reward: -1.12\n",
      "Episode: 1353, Score: 16.0, Avg reward: -0.88\n",
      "Episode: 1354, Score: 8.0, Avg reward: -0.78\n",
      "Episode: 1355, Score: -32.0, Avg reward: -0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1356, Score: 14.0, Avg reward: -0.80\n",
      "Episode: 1357, Score: 8.0, Avg reward: -0.56\n",
      "Episode: 1358, Score: -14.0, Avg reward: -0.74\n",
      "Episode: 1359, Score: -8.0, Avg reward: -1.06\n",
      "Episode: 1360, Score: -4.0, Avg reward: -1.18\n",
      "Episode: 1361, Score: 12.0, Avg reward: -1.18\n",
      "Episode: 1362, Score: 22.0, Avg reward: -0.92\n",
      "Episode: 1363, Score: 6.0, Avg reward: -0.66\n",
      "Episode: 1364, Score: -4.0, Avg reward: -0.84\n",
      "Episode: 1365, Score: 24.0, Avg reward: -0.34\n",
      "Episode: 1366, Score: 2.0, Avg reward: 0.00\n",
      "Episode: 1367, Score: -36.0, Avg reward: 0.02\n",
      "Episode: 1368, Score: 6.0, Avg reward: -0.04\n",
      "Episode: 1369, Score: 6.0, Avg reward: 0.20\n",
      "Episode: 1370, Score: 6.0, Avg reward: 0.22\n",
      "Episode: 1371, Score: -20.0, Avg reward: 0.36\n",
      "Episode: 1372, Score: 16.0, Avg reward: 0.56\n",
      "Episode: 1373, Score: -16.0, Avg reward: 0.74\n",
      "Episode: 1374, Score: 28.0, Avg reward: 0.92\n",
      "Episode: 1375, Score: -8.0, Avg reward: 0.80\n",
      "Episode: 1376, Score: 0.0, Avg reward: 0.50\n",
      "Episode: 1377, Score: 2.0, Avg reward: 0.42\n",
      "Episode: 1378, Score: 10.0, Avg reward: 0.64\n",
      "Episode: 1379, Score: 10.0, Avg reward: 0.74\n",
      "Episode: 1380, Score: -4.0, Avg reward: 0.74\n",
      "Episode: 1381, Score: -26.0, Avg reward: 0.42\n",
      "Episode: 1382, Score: -10.0, Avg reward: 0.56\n",
      "Episode: 1383, Score: 4.0, Avg reward: 0.62\n",
      "Episode: 1384, Score: 22.0, Avg reward: 0.90\n",
      "Episode: 1385, Score: -30.0, Avg reward: 0.56\n",
      "Episode: 1386, Score: 42.0, Avg reward: 1.06\n",
      "Episode: 1387, Score: 4.0, Avg reward: 0.86\n",
      "Episode: 1388, Score: -2.0, Avg reward: 0.56\n",
      "Episode: 1389, Score: 24.0, Avg reward: 0.82\n",
      "Episode: 1390, Score: 18.0, Avg reward: 1.16\n",
      "Episode: 1391, Score: 34.0, Avg reward: 1.60\n",
      "Episode: 1392, Score: -16.0, Avg reward: 1.64\n",
      "Episode: 1393, Score: 8.0, Avg reward: 1.94\n",
      "Episode: 1394, Score: -36.0, Avg reward: 1.58\n",
      "Episode: 1395, Score: -26.0, Avg reward: 1.16\n",
      "Episode: 1396, Score: -24.0, Avg reward: 0.86\n",
      "Episode: 1397, Score: -10.0, Avg reward: 0.70\n",
      "Episode: 1398, Score: 4.0, Avg reward: 0.54\n",
      "Episode: 1399, Score: -42.0, Avg reward: 0.48\n",
      "Episode: 1400, Score: -6.0, Avg reward: 0.38\n",
      "Episode: 1401, Score: 30.0, Avg reward: 1.16\n",
      "Episode: 1402, Score: 2.0, Avg reward: 1.08\n",
      "Episode: 1403, Score: 4.0, Avg reward: 1.08\n",
      "Episode: 1404, Score: -2.0, Avg reward: 1.18\n",
      "Episode: 1405, Score: 28.0, Avg reward: 1.38\n",
      "Episode: 1406, Score: 12.0, Avg reward: 1.44\n",
      "Episode: 1407, Score: 16.0, Avg reward: 1.48\n",
      "Episode: 1408, Score: 10.0, Avg reward: 1.54\n",
      "Episode: 1409, Score: 24.0, Avg reward: 1.98\n",
      "Episode: 1410, Score: -2.0, Avg reward: 2.40\n",
      "Episode: 1411, Score: 26.0, Avg reward: 2.48\n",
      "Episode: 1412, Score: -2.0, Avg reward: 2.46\n",
      "Episode: 1413, Score: 8.0, Avg reward: 2.66\n",
      "Episode: 1414, Score: 8.0, Avg reward: 2.68\n",
      "Episode: 1415, Score: 18.0, Avg reward: 2.80\n",
      "Episode: 1416, Score: -10.0, Avg reward: 2.68\n",
      "Episode: 1417, Score: -38.0, Avg reward: 2.58\n",
      "Episode: 1418, Score: -4.0, Avg reward: 2.40\n",
      "Episode: 1419, Score: 22.0, Avg reward: 2.72\n",
      "Episode: 1420, Score: -26.0, Avg reward: 2.32\n",
      "Episode: 1421, Score: 6.0, Avg reward: 2.42\n",
      "Episode: 1422, Score: 12.0, Avg reward: 2.38\n",
      "Episode: 1423, Score: 30.0, Avg reward: 2.78\n",
      "Episode: 1424, Score: -40.0, Avg reward: 2.20\n",
      "Episode: 1425, Score: -12.0, Avg reward: 2.20\n",
      "Episode: 1426, Score: 8.0, Avg reward: 1.90\n",
      "Episode: 1427, Score: 26.0, Avg reward: 2.34\n",
      "Episode: 1428, Score: -34.0, Avg reward: 2.02\n",
      "Episode: 1429, Score: 22.0, Avg reward: 2.22\n",
      "Episode: 1430, Score: 14.0, Avg reward: 2.12\n",
      "Episode: 1431, Score: -14.0, Avg reward: 1.84\n",
      "Episode: 1432, Score: 20.0, Avg reward: 1.90\n",
      "Episode: 1433, Score: -6.0, Avg reward: 1.68\n",
      "Episode: 1434, Score: -10.0, Avg reward: 1.46\n",
      "Episode: 1435, Score: 8.0, Avg reward: 1.54\n",
      "Episode: 1436, Score: 8.0, Avg reward: 1.44\n",
      "Episode: 1437, Score: 0.0, Avg reward: 1.24\n",
      "Episode: 1438, Score: -32.0, Avg reward: 0.64\n",
      "Episode: 1439, Score: 8.0, Avg reward: 1.16\n",
      "Episode: 1440, Score: -16.0, Avg reward: 0.92\n",
      "Episode: 1441, Score: -42.0, Avg reward: 0.62\n",
      "Episode: 1442, Score: -30.0, Avg reward: 0.28\n",
      "Episode: 1443, Score: 34.0, Avg reward: 0.36\n",
      "Episode: 1444, Score: -36.0, Avg reward: 0.22\n",
      "Episode: 1445, Score: 2.0, Avg reward: 0.24\n",
      "Episode: 1446, Score: 22.0, Avg reward: 0.36\n",
      "Episode: 1447, Score: 18.0, Avg reward: 0.34\n",
      "Episode: 1448, Score: -16.0, Avg reward: 0.18\n",
      "Episode: 1449, Score: 14.0, Avg reward: 0.22\n",
      "Episode: 1450, Score: 18.0, Avg reward: 0.46\n",
      "Episode: 1451, Score: 12.0, Avg reward: 0.58\n",
      "Episode: 1452, Score: 20.0, Avg reward: 1.20\n",
      "Episode: 1453, Score: 8.0, Avg reward: 1.12\n",
      "Episode: 1454, Score: -4.0, Avg reward: 1.00\n",
      "Episode: 1455, Score: 2.0, Avg reward: 1.34\n",
      "Episode: 1456, Score: -10.0, Avg reward: 1.10\n",
      "Episode: 1457, Score: -14.0, Avg reward: 0.88\n",
      "Episode: 1458, Score: 6.0, Avg reward: 1.08\n",
      "Episode: 1459, Score: -30.0, Avg reward: 0.86\n",
      "Episode: 1460, Score: 10.0, Avg reward: 1.00\n",
      "Episode: 1461, Score: -22.0, Avg reward: 0.66\n",
      "Episode: 1462, Score: 4.0, Avg reward: 0.48\n",
      "Episode: 1463, Score: -38.0, Avg reward: 0.04\n",
      "Episode: 1464, Score: 2.0, Avg reward: 0.10\n",
      "Episode: 1465, Score: 8.0, Avg reward: -0.06\n",
      "Episode: 1466, Score: 2.0, Avg reward: -0.06\n",
      "Episode: 1467, Score: 36.0, Avg reward: 0.66\n",
      "Episode: 1468, Score: 22.0, Avg reward: 0.82\n",
      "Episode: 1469, Score: 10.0, Avg reward: 0.86\n",
      "Episode: 1470, Score: 24.0, Avg reward: 1.04\n",
      "Episode: 1471, Score: 16.0, Avg reward: 1.40\n",
      "Episode: 1472, Score: 16.0, Avg reward: 1.40\n",
      "Episode: 1473, Score: 20.0, Avg reward: 1.76\n",
      "Episode: 1474, Score: 28.0, Avg reward: 1.76\n",
      "Episode: 1475, Score: 20.0, Avg reward: 2.04\n",
      "Episode: 1476, Score: 8.0, Avg reward: 2.12\n",
      "Episode: 1477, Score: -4.0, Avg reward: 2.06\n",
      "Episode: 1478, Score: 8.0, Avg reward: 2.04\n",
      "Episode: 1479, Score: 14.0, Avg reward: 2.08\n",
      "Episode: 1480, Score: 24.0, Avg reward: 2.36\n",
      "Episode: 1481, Score: -42.0, Avg reward: 2.20\n",
      "Episode: 1482, Score: -22.0, Avg reward: 2.08\n",
      "Episode: 1483, Score: -6.0, Avg reward: 1.98\n",
      "Episode: 1484, Score: -16.0, Avg reward: 1.60\n",
      "Episode: 1485, Score: 8.0, Avg reward: 1.98\n",
      "Episode: 1486, Score: 20.0, Avg reward: 1.76\n",
      "Episode: 1487, Score: 14.0, Avg reward: 1.86\n",
      "Episode: 1488, Score: -2.0, Avg reward: 1.86\n",
      "Episode: 1489, Score: 20.0, Avg reward: 1.82\n",
      "Episode: 1490, Score: 2.0, Avg reward: 1.66\n",
      "Episode: 1491, Score: 22.0, Avg reward: 1.54\n",
      "Episode: 1492, Score: -10.0, Avg reward: 1.60\n",
      "Episode: 1493, Score: 10.0, Avg reward: 1.62\n",
      "Episode: 1494, Score: 8.0, Avg reward: 2.06\n",
      "Episode: 1495, Score: 16.0, Avg reward: 2.48\n",
      "Episode: 1496, Score: -6.0, Avg reward: 2.66\n",
      "Episode: 1497, Score: 32.0, Avg reward: 3.08\n",
      "Episode: 1498, Score: 14.0, Avg reward: 3.18\n",
      "Episode: 1499, Score: 16.0, Avg reward: 3.76\n",
      "Episode: 1500, Score: -40.0, Avg reward: 3.42\n",
      "Episode: 1501, Score: 6.0, Avg reward: 3.18\n",
      "Episode: 1502, Score: 34.0, Avg reward: 3.50\n",
      "Episode: 1503, Score: -18.0, Avg reward: 3.28\n",
      "Episode: 1504, Score: 18.0, Avg reward: 3.48\n",
      "Episode: 1505, Score: 4.0, Avg reward: 3.24\n",
      "Episode: 1506, Score: 20.0, Avg reward: 3.32\n",
      "Episode: 1507, Score: 20.0, Avg reward: 3.36\n",
      "Episode: 1508, Score: 4.0, Avg reward: 3.30\n",
      "Episode: 1509, Score: -42.0, Avg reward: 2.64\n",
      "Episode: 1510, Score: 20.0, Avg reward: 2.86\n",
      "Episode: 1511, Score: 2.0, Avg reward: 2.62\n",
      "Episode: 1512, Score: -8.0, Avg reward: 2.56\n",
      "Episode: 1513, Score: -24.0, Avg reward: 2.24\n",
      "Episode: 1514, Score: 22.0, Avg reward: 2.38\n",
      "Episode: 1515, Score: 10.0, Avg reward: 2.30\n",
      "Episode: 1516, Score: -44.0, Avg reward: 1.96\n",
      "Episode: 1517, Score: 20.0, Avg reward: 2.54\n",
      "Episode: 1518, Score: 14.0, Avg reward: 2.72\n",
      "Episode: 1519, Score: 4.0, Avg reward: 2.54\n",
      "Episode: 1520, Score: -4.0, Avg reward: 2.76\n",
      "Episode: 1521, Score: -44.0, Avg reward: 2.26\n",
      "Episode: 1522, Score: 4.0, Avg reward: 2.18\n",
      "Episode: 1523, Score: 4.0, Avg reward: 1.92\n",
      "Episode: 1524, Score: 18.0, Avg reward: 2.50\n",
      "Episode: 1525, Score: -4.0, Avg reward: 2.58\n",
      "Episode: 1526, Score: -8.0, Avg reward: 2.42\n",
      "Episode: 1527, Score: -42.0, Avg reward: 1.74\n",
      "Episode: 1528, Score: 6.0, Avg reward: 2.14\n",
      "Episode: 1529, Score: 2.0, Avg reward: 1.94\n",
      "Episode: 1530, Score: -16.0, Avg reward: 1.64\n",
      "Episode: 1531, Score: -32.0, Avg reward: 1.46\n",
      "Episode: 1532, Score: 12.0, Avg reward: 1.38\n",
      "Episode: 1533, Score: -22.0, Avg reward: 1.22\n",
      "Episode: 1534, Score: 4.0, Avg reward: 1.36\n",
      "Episode: 1535, Score: 34.0, Avg reward: 1.62\n",
      "Episode: 1536, Score: 6.0, Avg reward: 1.60\n",
      "Episode: 1537, Score: 18.0, Avg reward: 1.78\n",
      "Episode: 1538, Score: -2.0, Avg reward: 2.08\n",
      "Episode: 1539, Score: 10.0, Avg reward: 2.10\n",
      "Episode: 1540, Score: 18.0, Avg reward: 2.44\n",
      "Episode: 1541, Score: 16.0, Avg reward: 3.02\n",
      "Episode: 1542, Score: 20.0, Avg reward: 3.52\n",
      "Episode: 1543, Score: -42.0, Avg reward: 2.76\n",
      "Episode: 1544, Score: -4.0, Avg reward: 3.08\n",
      "Episode: 1545, Score: -32.0, Avg reward: 2.74\n",
      "Episode: 1546, Score: 10.0, Avg reward: 2.62\n",
      "Episode: 1547, Score: -22.0, Avg reward: 2.22\n",
      "Episode: 1548, Score: 14.0, Avg reward: 2.52\n",
      "Episode: 1549, Score: 32.0, Avg reward: 2.70\n",
      "Episode: 1550, Score: 8.0, Avg reward: 2.60\n",
      "Episode: 1551, Score: 2.0, Avg reward: 2.50\n",
      "Episode: 1552, Score: 22.0, Avg reward: 2.52\n",
      "Episode: 1553, Score: 28.0, Avg reward: 2.72\n",
      "Episode: 1554, Score: -8.0, Avg reward: 2.68\n",
      "Episode: 1555, Score: 24.0, Avg reward: 2.90\n",
      "Episode: 1556, Score: -4.0, Avg reward: 2.96\n",
      "Episode: 1557, Score: 16.0, Avg reward: 3.26\n",
      "Episode: 1558, Score: 30.0, Avg reward: 3.50\n",
      "Episode: 1559, Score: -2.0, Avg reward: 3.78\n",
      "Episode: 1560, Score: 10.0, Avg reward: 3.78\n",
      "Episode: 1561, Score: 36.0, Avg reward: 4.36\n",
      "Episode: 1562, Score: 36.0, Avg reward: 4.68\n",
      "Episode: 1563, Score: 4.0, Avg reward: 5.10\n",
      "Episode: 1564, Score: -6.0, Avg reward: 5.02\n",
      "Episode: 1565, Score: 2.0, Avg reward: 4.96\n",
      "Episode: 1566, Score: 4.0, Avg reward: 4.98\n",
      "Episode: 1567, Score: 26.0, Avg reward: 4.88\n",
      "Episode: 1568, Score: 16.0, Avg reward: 4.82\n",
      "Episode: 1569, Score: 26.0, Avg reward: 4.98\n",
      "Episode: 1570, Score: 34.0, Avg reward: 5.08\n",
      "Episode: 1571, Score: 26.0, Avg reward: 5.18\n",
      "Episode: 1572, Score: 22.0, Avg reward: 5.24\n",
      "Episode: 1573, Score: -4.0, Avg reward: 5.00\n",
      "Episode: 1574, Score: 20.0, Avg reward: 4.92\n",
      "Episode: 1575, Score: 4.0, Avg reward: 4.76\n",
      "Episode: 1576, Score: 4.0, Avg reward: 4.72\n",
      "Episode: 1577, Score: 22.0, Avg reward: 4.98\n",
      "Episode: 1578, Score: 26.0, Avg reward: 5.16\n",
      "Episode: 1579, Score: -38.0, Avg reward: 4.64\n",
      "Episode: 1580, Score: 16.0, Avg reward: 4.56\n",
      "Episode: 1581, Score: 30.0, Avg reward: 5.28\n",
      "Episode: 1582, Score: 6.0, Avg reward: 5.56\n",
      "Episode: 1583, Score: -18.0, Avg reward: 5.44\n",
      "Episode: 1584, Score: 30.0, Avg reward: 5.90\n",
      "Episode: 1585, Score: 6.0, Avg reward: 5.88\n",
      "Episode: 1586, Score: 28.0, Avg reward: 5.96\n",
      "Episode: 1587, Score: 6.0, Avg reward: 5.88\n",
      "Episode: 1588, Score: 8.0, Avg reward: 5.98\n",
      "Episode: 1589, Score: -28.0, Avg reward: 5.50\n",
      "Episode: 1590, Score: 4.0, Avg reward: 5.52\n",
      "Episode: 1591, Score: 34.0, Avg reward: 5.64\n",
      "Episode: 1592, Score: 16.0, Avg reward: 5.90\n",
      "Episode: 1593, Score: -22.0, Avg reward: 5.58\n",
      "Episode: 1594, Score: -4.0, Avg reward: 5.46\n",
      "Episode: 1595, Score: 6.0, Avg reward: 5.36\n",
      "Episode: 1596, Score: 22.0, Avg reward: 5.64\n",
      "Episode: 1597, Score: 8.0, Avg reward: 5.40\n",
      "Episode: 1598, Score: 32.0, Avg reward: 5.58\n",
      "Episode: 1599, Score: 4.0, Avg reward: 5.46\n",
      "Episode: 1600, Score: -14.0, Avg reward: 5.72\n",
      "Episode: 1601, Score: -6.0, Avg reward: 5.60\n",
      "Episode: 1602, Score: 36.0, Avg reward: 5.62\n",
      "Episode: 1603, Score: 0.0, Avg reward: 5.80\n",
      "Episode: 1604, Score: 10.0, Avg reward: 5.72\n",
      "Episode: 1605, Score: 8.0, Avg reward: 5.76\n",
      "Episode: 1606, Score: 14.0, Avg reward: 5.70\n",
      "Episode: 1607, Score: 24.0, Avg reward: 5.74\n",
      "Episode: 1608, Score: 0.0, Avg reward: 5.70\n",
      "Episode: 1609, Score: 22.0, Avg reward: 6.34\n",
      "Episode: 1610, Score: -12.0, Avg reward: 6.02\n",
      "Episode: 1611, Score: 16.0, Avg reward: 6.16\n",
      "Episode: 1612, Score: 32.0, Avg reward: 6.56\n",
      "Episode: 1613, Score: 4.0, Avg reward: 6.84\n",
      "Episode: 1614, Score: 8.0, Avg reward: 6.70\n",
      "Episode: 1615, Score: 0.0, Avg reward: 6.60\n",
      "Episode: 1616, Score: -8.0, Avg reward: 6.96\n",
      "Episode: 1617, Score: 6.0, Avg reward: 6.82\n",
      "Episode: 1618, Score: 0.0, Avg reward: 6.68\n",
      "Episode: 1619, Score: 14.0, Avg reward: 6.78\n",
      "Episode: 1620, Score: 4.0, Avg reward: 6.86\n",
      "Episode: 1621, Score: 0.0, Avg reward: 7.30\n",
      "Episode: 1622, Score: 10.0, Avg reward: 7.36\n",
      "Episode: 1623, Score: 20.0, Avg reward: 7.52\n",
      "Episode: 1624, Score: 0.0, Avg reward: 7.34\n",
      "Episode: 1625, Score: 32.0, Avg reward: 7.70\n",
      "Episode: 1626, Score: 4.0, Avg reward: 7.82\n",
      "Episode: 1627, Score: 16.0, Avg reward: 8.40\n",
      "Episode: 1628, Score: 16.0, Avg reward: 8.50\n",
      "Episode: 1629, Score: 20.0, Avg reward: 8.68\n",
      "Episode: 1630, Score: 24.0, Avg reward: 9.08\n",
      "Episode: 1631, Score: -2.0, Avg reward: 9.38\n",
      "Episode: 1632, Score: 14.0, Avg reward: 9.40\n",
      "Episode: 1633, Score: 0.0, Avg reward: 9.62\n",
      "Episode: 1634, Score: -4.0, Avg reward: 9.54\n",
      "Episode: 1635, Score: -4.0, Avg reward: 9.16\n",
      "Episode: 1636, Score: -2.0, Avg reward: 9.08\n",
      "Episode: 1637, Score: -18.0, Avg reward: 8.72\n",
      "Episode: 1638, Score: 10.0, Avg reward: 8.84\n",
      "Episode: 1639, Score: 6.0, Avg reward: 8.80\n",
      "Episode: 1640, Score: 10.0, Avg reward: 8.72\n",
      "Episode: 1641, Score: 30.0, Avg reward: 8.86\n",
      "Episode: 1642, Score: -2.0, Avg reward: 8.64\n",
      "Episode: 1643, Score: -4.0, Avg reward: 9.02\n",
      "Episode: 1644, Score: -20.0, Avg reward: 8.86\n",
      "Episode: 1645, Score: 20.0, Avg reward: 9.38\n",
      "Episode: 1646, Score: 26.0, Avg reward: 9.54\n",
      "Episode: 1647, Score: 22.0, Avg reward: 9.98\n",
      "Episode: 1648, Score: 38.0, Avg reward: 10.22\n",
      "Episode: 1649, Score: 12.0, Avg reward: 10.02\n",
      "Episode: 1650, Score: -2.0, Avg reward: 9.92\n",
      "Episode: 1651, Score: 6.0, Avg reward: 9.96\n",
      "Episode: 1652, Score: 30.0, Avg reward: 10.04\n",
      "Episode: 1653, Score: 2.0, Avg reward: 9.78\n",
      "Episode: 1654, Score: -26.0, Avg reward: 9.60\n",
      "Episode: 1655, Score: 14.0, Avg reward: 9.50\n",
      "Episode: 1656, Score: 34.0, Avg reward: 9.88\n",
      "Episode: 1657, Score: 30.0, Avg reward: 10.02\n",
      "Episode: 1658, Score: 16.0, Avg reward: 9.88\n",
      "Episode: 1659, Score: 24.0, Avg reward: 10.14\n",
      "Episode: 1660, Score: 0.0, Avg reward: 10.04\n",
      "Episode: 1661, Score: 20.0, Avg reward: 9.88\n",
      "Episode: 1662, Score: 4.0, Avg reward: 9.56\n",
      "Episode: 1663, Score: 24.0, Avg reward: 9.76\n",
      "Episode: 1664, Score: -14.0, Avg reward: 9.68\n",
      "Episode: 1665, Score: 10.0, Avg reward: 9.76\n",
      "Episode: 1666, Score: 16.0, Avg reward: 9.88\n",
      "Episode: 1667, Score: 22.0, Avg reward: 9.84\n",
      "Episode: 1668, Score: 4.0, Avg reward: 9.72\n",
      "Episode: 1669, Score: -34.0, Avg reward: 9.12\n",
      "Episode: 1670, Score: 40.0, Avg reward: 9.18\n",
      "Episode: 1671, Score: 18.0, Avg reward: 9.10\n",
      "Episode: 1672, Score: 42.0, Avg reward: 9.30\n",
      "Episode: 1673, Score: 30.0, Avg reward: 9.64\n",
      "Episode: 1674, Score: 28.0, Avg reward: 9.72\n",
      "Episode: 1675, Score: -44.0, Avg reward: 9.24\n",
      "Episode: 1676, Score: 42.0, Avg reward: 9.62\n",
      "Episode: 1677, Score: 42.0, Avg reward: 9.82\n",
      "Episode: 1678, Score: 40.0, Avg reward: 9.96\n",
      "Episode: 1679, Score: 40.0, Avg reward: 10.74\n",
      "Episode: 1680, Score: 6.0, Avg reward: 10.64\n",
      "Episode: 1681, Score: 24.0, Avg reward: 10.58\n",
      "Episode: 1682, Score: 30.0, Avg reward: 10.82\n",
      "Episode: 1683, Score: -16.0, Avg reward: 10.84\n",
      "Episode: 1684, Score: 28.0, Avg reward: 10.82\n",
      "Episode: 1685, Score: 24.0, Avg reward: 11.00\n",
      "Episode: 1686, Score: 26.0, Avg reward: 10.98\n",
      "Episode: 1687, Score: 32.0, Avg reward: 11.24\n",
      "Episode: 1688, Score: 2.0, Avg reward: 11.18\n",
      "Episode: 1689, Score: 44.0, Avg reward: 11.90\n",
      "Episode: 1690, Score: 42.0, Avg reward: 12.28\n",
      "Episode: 1691, Score: 40.0, Avg reward: 12.34\n",
      "Episode: 1692, Score: 40.0, Avg reward: 12.58\n",
      "Episode: 1693, Score: 40.0, Avg reward: 13.20\n",
      "Episode: 1694, Score: -8.0, Avg reward: 13.16\n",
      "Episode: 1695, Score: 14.0, Avg reward: 13.24\n",
      "Episode: 1696, Score: 22.0, Avg reward: 13.24\n",
      "Episode: 1697, Score: 38.0, Avg reward: 13.54\n",
      "Episode: 1698, Score: 46.0, Avg reward: 13.68\n",
      "Episode: 1699, Score: 20.0, Avg reward: 13.84\n",
      "Episode: 1700, Score: 42.0, Avg reward: 14.40\n",
      "Episode: 1701, Score: -6.0, Avg reward: 14.40\n",
      "Episode: 1702, Score: 0.0, Avg reward: 14.04\n",
      "Episode: 1703, Score: 26.0, Avg reward: 14.30\n",
      "Episode: 1704, Score: 18.0, Avg reward: 14.38\n",
      "Episode: 1705, Score: 32.0, Avg reward: 14.62\n",
      "Episode: 1706, Score: 10.0, Avg reward: 14.58\n",
      "Episode: 1707, Score: 12.0, Avg reward: 14.46\n",
      "Episode: 1708, Score: 44.0, Avg reward: 14.90\n",
      "Episode: 1709, Score: 18.0, Avg reward: 14.86\n",
      "Episode: 1710, Score: 24.0, Avg reward: 15.22\n",
      "Episode: 1711, Score: 16.0, Avg reward: 15.22\n",
      "Episode: 1712, Score: 36.0, Avg reward: 15.26\n",
      "Episode: 1713, Score: 48.0, Avg reward: 15.70\n",
      "Episode: 1714, Score: -6.0, Avg reward: 15.56\n",
      "Episode: 1715, Score: 16.0, Avg reward: 15.72\n",
      "Episode: 1716, Score: 42.0, Avg reward: 16.22\n",
      "Episode: 1717, Score: 14.0, Avg reward: 16.30\n",
      "Episode: 1718, Score: 28.0, Avg reward: 16.58\n",
      "Episode: 1719, Score: 36.0, Avg reward: 16.80\n",
      "Episode: 1720, Score: -16.0, Avg reward: 16.60\n",
      "Episode: 1721, Score: 12.0, Avg reward: 16.72\n",
      "Episode: 1722, Score: 44.0, Avg reward: 17.06\n",
      "Episode: 1723, Score: 42.0, Avg reward: 17.28\n",
      "Episode: 1724, Score: -44.0, Avg reward: 16.84\n",
      "Episode: 1725, Score: 4.0, Avg reward: 16.56\n",
      "Episode: 1726, Score: 48.0, Avg reward: 17.00\n",
      "Episode: 1727, Score: 47.0, Avg reward: 17.31\n",
      "Episode: 1728, Score: 44.0, Avg reward: 17.59\n",
      "Episode: 1729, Score: 30.0, Avg reward: 17.69\n",
      "Episode: 1730, Score: 48.0, Avg reward: 17.93\n",
      "Episode: 1731, Score: 24.0, Avg reward: 18.19\n",
      "Episode: 1732, Score: 30.0, Avg reward: 18.35\n",
      "Episode: 1733, Score: 10.0, Avg reward: 18.45\n",
      "Episode: 1734, Score: -6.0, Avg reward: 18.43\n",
      "Episode: 1735, Score: 14.0, Avg reward: 18.61\n",
      "Episode: 1736, Score: -4.0, Avg reward: 18.59\n",
      "Episode: 1737, Score: 48.0, Avg reward: 19.25\n",
      "Episode: 1738, Score: 36.0, Avg reward: 19.51\n",
      "Episode: 1739, Score: 38.0, Avg reward: 19.83\n",
      "Episode: 1740, Score: 42.0, Avg reward: 20.15\n",
      "Episode: 1741, Score: 28.0, Avg reward: 20.13\n",
      "Episode: 1742, Score: 4.0, Avg reward: 20.19\n",
      "Episode: 1743, Score: 46.0, Avg reward: 20.69\n",
      "Episode: 1744, Score: -4.0, Avg reward: 20.85\n",
      "Episode: 1745, Score: 10.0, Avg reward: 20.75\n",
      "Episode: 1746, Score: -30.0, Avg reward: 20.19\n",
      "Episode: 1747, Score: 38.0, Avg reward: 20.35\n",
      "Episode: 1748, Score: -36.0, Avg reward: 19.61\n",
      "Episode: 1749, Score: 46.0, Avg reward: 19.95\n",
      "Episode: 1750, Score: 46.0, Avg reward: 20.43\n",
      "Episode: 1751, Score: 26.0, Avg reward: 20.63\n",
      "Episode: 1752, Score: 40.0, Avg reward: 20.73\n",
      "Episode: 1753, Score: 48.0, Avg reward: 21.19\n",
      "Episode: 1754, Score: 44.0, Avg reward: 21.89\n",
      "Episode: 1755, Score: 42.0, Avg reward: 22.17\n",
      "Episode: 1756, Score: 48.0, Avg reward: 22.31\n",
      "Episode: 1757, Score: 8.0, Avg reward: 22.09\n",
      "Episode: 1758, Score: 48.0, Avg reward: 22.41\n",
      "Episode: 1759, Score: 40.0, Avg reward: 22.57\n",
      "Episode: 1760, Score: 32.0, Avg reward: 22.89\n",
      "Episode: 1761, Score: 46.0, Avg reward: 23.15\n",
      "Episode: 1762, Score: 48.0, Avg reward: 23.59\n",
      "Episode: 1763, Score: 48.0, Avg reward: 23.83\n",
      "Episode: 1764, Score: 6.0, Avg reward: 24.03\n",
      "Episode: 1765, Score: 48.0, Avg reward: 24.41\n",
      "Episode: 1766, Score: -10.0, Avg reward: 24.15\n",
      "Episode: 1767, Score: -8.0, Avg reward: 23.85\n",
      "Episode: 1768, Score: 48.0, Avg reward: 24.29\n",
      "Episode: 1769, Score: 48.0, Avg reward: 25.11\n",
      "Episode: 1770, Score: 48.0, Avg reward: 25.19\n",
      "Episode: 1771, Score: 48.0, Avg reward: 25.49\n",
      "Episode: 1772, Score: -34.0, Avg reward: 24.73\n",
      "Episode: 1773, Score: 28.0, Avg reward: 24.71\n",
      "Episode: 1774, Score: -30.0, Avg reward: 24.13\n",
      "Episode: 1775, Score: 48.0, Avg reward: 25.05\n",
      "Episode: 1776, Score: -34.0, Avg reward: 24.29\n",
      "Episode: 1777, Score: -22.0, Avg reward: 23.65\n",
      "Episode: 1778, Score: -16.0, Avg reward: 23.09\n",
      "Episode: 1779, Score: -36.0, Avg reward: 22.33\n",
      "Episode: 1780, Score: 42.0, Avg reward: 22.69\n",
      "Episode: 1781, Score: 14.0, Avg reward: 22.59\n",
      "Episode: 1782, Score: -10.0, Avg reward: 22.19\n",
      "Episode: 1783, Score: 22.0, Avg reward: 22.57\n",
      "Episode: 1784, Score: 10.0, Avg reward: 22.39\n",
      "Episode: 1785, Score: 48.0, Avg reward: 22.63\n",
      "Episode: 1786, Score: 48.0, Avg reward: 22.85\n",
      "Episode: 1787, Score: 18.0, Avg reward: 22.71\n",
      "Episode: 1788, Score: 48.0, Avg reward: 23.17\n",
      "Episode: 1789, Score: 48.0, Avg reward: 23.21\n",
      "Episode: 1790, Score: -28.0, Avg reward: 22.51\n",
      "Episode: 1791, Score: 48.0, Avg reward: 22.59\n",
      "Episode: 1792, Score: 48.0, Avg reward: 22.67\n",
      "Episode: 1793, Score: 39.0, Avg reward: 22.66\n",
      "Episode: 1794, Score: -12.0, Avg reward: 22.62\n",
      "Episode: 1795, Score: -8.0, Avg reward: 22.40\n",
      "Episode: 1796, Score: 48.0, Avg reward: 22.66\n",
      "Episode: 1797, Score: -34.0, Avg reward: 21.94\n",
      "Episode: 1798, Score: 4.0, Avg reward: 21.52\n",
      "Episode: 1799, Score: 48.0, Avg reward: 21.80\n",
      "Episode: 1800, Score: 10.0, Avg reward: 21.48\n",
      "Episode: 1801, Score: 18.0, Avg reward: 21.72\n",
      "Episode: 1802, Score: 48.0, Avg reward: 22.20\n",
      "Episode: 1803, Score: -4.0, Avg reward: 21.90\n",
      "Episode: 1804, Score: -6.0, Avg reward: 21.66\n",
      "Episode: 1805, Score: 48.0, Avg reward: 21.82\n",
      "Episode: 1806, Score: 48.0, Avg reward: 22.20\n",
      "Episode: 1807, Score: 12.0, Avg reward: 22.20\n",
      "Episode: 1808, Score: 2.0, Avg reward: 21.78\n",
      "Episode: 1809, Score: 2.0, Avg reward: 21.62\n",
      "Episode: 1810, Score: -28.0, Avg reward: 21.10\n",
      "Episode: 1811, Score: 40.0, Avg reward: 21.34\n",
      "Episode: 1812, Score: 48.0, Avg reward: 21.46\n",
      "Episode: 1813, Score: 48.0, Avg reward: 21.46\n",
      "Episode: 1814, Score: 2.0, Avg reward: 21.54\n",
      "Episode: 1815, Score: 48.0, Avg reward: 21.86\n",
      "Episode: 1816, Score: -40.0, Avg reward: 21.04\n",
      "Episode: 1817, Score: -12.0, Avg reward: 20.78\n",
      "Episode: 1818, Score: -6.0, Avg reward: 20.44\n",
      "Episode: 1819, Score: 12.0, Avg reward: 20.20\n",
      "Episode: 1820, Score: 48.0, Avg reward: 20.84\n",
      "Episode: 1821, Score: 48.0, Avg reward: 21.20\n",
      "Episode: 1822, Score: 48.0, Avg reward: 21.24\n",
      "Episode: 1823, Score: 48.0, Avg reward: 21.30\n",
      "Episode: 1824, Score: 48.0, Avg reward: 22.22\n",
      "Episode: 1825, Score: 48.0, Avg reward: 22.66\n",
      "Episode: 1826, Score: 4.0, Avg reward: 22.22\n",
      "Episode: 1827, Score: 8.0, Avg reward: 21.83\n",
      "Episode: 1828, Score: 6.0, Avg reward: 21.45\n",
      "Episode: 1829, Score: -30.0, Avg reward: 20.85\n",
      "Episode: 1830, Score: 48.0, Avg reward: 20.85\n",
      "Episode: 1831, Score: 8.0, Avg reward: 20.69\n",
      "Episode: 1832, Score: -30.0, Avg reward: 20.09\n",
      "Episode: 1833, Score: -32.0, Avg reward: 19.67\n",
      "Episode: 1834, Score: 48.0, Avg reward: 20.21\n",
      "Episode: 1835, Score: -2.0, Avg reward: 20.05\n",
      "Episode: 1836, Score: 48.0, Avg reward: 20.57\n",
      "Episode: 1837, Score: 40.0, Avg reward: 20.49\n",
      "Episode: 1838, Score: 0.0, Avg reward: 20.13\n",
      "Episode: 1839, Score: 48.0, Avg reward: 20.23\n",
      "Episode: 1840, Score: -46.0, Avg reward: 19.35\n",
      "Episode: 1841, Score: -14.0, Avg reward: 18.93\n",
      "Episode: 1842, Score: 2.0, Avg reward: 18.91\n",
      "Episode: 1843, Score: -40.0, Avg reward: 18.05\n",
      "Episode: 1844, Score: 48.0, Avg reward: 18.57\n",
      "Episode: 1845, Score: 48.0, Avg reward: 18.95\n",
      "Episode: 1846, Score: 48.0, Avg reward: 19.73\n",
      "Episode: 1847, Score: -12.0, Avg reward: 19.23\n",
      "Episode: 1848, Score: -26.0, Avg reward: 19.33\n",
      "Episode: 1849, Score: 48.0, Avg reward: 19.35\n",
      "Episode: 1850, Score: -22.0, Avg reward: 18.67\n",
      "Episode: 1851, Score: 42.0, Avg reward: 18.83\n",
      "Episode: 1852, Score: 10.0, Avg reward: 18.53\n",
      "Episode: 1853, Score: 28.0, Avg reward: 18.33\n",
      "Episode: 1854, Score: 48.0, Avg reward: 18.37\n",
      "Episode: 1855, Score: 48.0, Avg reward: 18.43\n",
      "Episode: 1856, Score: 30.0, Avg reward: 18.25\n",
      "Episode: 1857, Score: 2.0, Avg reward: 18.19\n",
      "Episode: 1858, Score: 48.0, Avg reward: 18.19\n",
      "Episode: 1859, Score: 48.0, Avg reward: 18.27\n",
      "Episode: 1860, Score: 48.0, Avg reward: 18.43\n",
      "Episode: 1861, Score: -48.0, Avg reward: 17.49\n",
      "Episode: 1862, Score: -14.0, Avg reward: 16.87\n",
      "Episode: 1863, Score: 48.0, Avg reward: 16.87\n",
      "Episode: 1864, Score: 48.0, Avg reward: 17.29\n",
      "Episode: 1865, Score: -34.0, Avg reward: 16.47\n",
      "Episode: 1866, Score: 14.0, Avg reward: 16.71\n",
      "Episode: 1867, Score: 40.0, Avg reward: 17.19\n",
      "Episode: 1868, Score: -40.0, Avg reward: 16.31\n",
      "Episode: 1869, Score: 40.0, Avg reward: 16.23\n",
      "Episode: 1870, Score: -8.0, Avg reward: 15.67\n",
      "Episode: 1871, Score: 48.0, Avg reward: 15.67\n",
      "Episode: 1872, Score: 8.0, Avg reward: 16.09\n",
      "Episode: 1873, Score: -22.0, Avg reward: 15.59\n",
      "Episode: 1874, Score: 48.0, Avg reward: 16.37\n",
      "Episode: 1875, Score: -8.0, Avg reward: 15.81\n",
      "Episode: 1876, Score: -48.0, Avg reward: 15.67\n",
      "Episode: 1877, Score: 10.0, Avg reward: 15.99\n",
      "Episode: 1878, Score: -24.0, Avg reward: 15.91\n",
      "Episode: 1879, Score: -18.0, Avg reward: 16.09\n",
      "Episode: 1880, Score: -48.0, Avg reward: 15.19\n",
      "Episode: 1881, Score: 48.0, Avg reward: 15.53\n",
      "Episode: 1882, Score: 26.0, Avg reward: 15.89\n",
      "Episode: 1883, Score: -18.0, Avg reward: 15.49\n",
      "Episode: 1884, Score: -6.0, Avg reward: 15.33\n",
      "Episode: 1885, Score: 48.0, Avg reward: 15.33\n",
      "Episode: 1886, Score: -32.0, Avg reward: 14.53\n",
      "Episode: 1887, Score: 10.0, Avg reward: 14.45\n",
      "Episode: 1888, Score: -10.0, Avg reward: 13.87\n",
      "Episode: 1889, Score: 46.0, Avg reward: 13.85\n",
      "Episode: 1890, Score: -48.0, Avg reward: 13.65\n",
      "Episode: 1891, Score: 48.0, Avg reward: 13.65\n",
      "Episode: 1892, Score: 48.0, Avg reward: 13.65\n",
      "Episode: 1893, Score: 48.0, Avg reward: 13.74\n",
      "Episode: 1894, Score: 16.0, Avg reward: 14.02\n",
      "Episode: 1895, Score: -2.0, Avg reward: 14.08\n",
      "Episode: 1896, Score: -22.0, Avg reward: 13.38\n",
      "Episode: 1897, Score: 46.0, Avg reward: 14.18\n",
      "Episode: 1898, Score: -6.0, Avg reward: 14.08\n",
      "Episode: 1899, Score: 2.0, Avg reward: 13.62\n",
      "Episode: 1900, Score: 48.0, Avg reward: 14.00\n",
      "Episode: 1901, Score: -2.0, Avg reward: 13.80\n",
      "Episode: 1902, Score: 6.0, Avg reward: 13.38\n",
      "Episode: 1903, Score: -2.0, Avg reward: 13.40\n",
      "Episode: 1904, Score: 48.0, Avg reward: 13.94\n",
      "Episode: 1905, Score: 48.0, Avg reward: 13.94\n",
      "Episode: 1906, Score: 48.0, Avg reward: 13.94\n",
      "Episode: 1907, Score: -12.0, Avg reward: 13.70\n",
      "Episode: 1908, Score: 18.0, Avg reward: 13.86\n",
      "Episode: 1909, Score: 22.0, Avg reward: 14.06\n",
      "Episode: 1910, Score: 48.0, Avg reward: 14.82\n",
      "Episode: 1911, Score: 48.0, Avg reward: 14.90\n",
      "Episode: 1912, Score: -6.0, Avg reward: 14.36\n",
      "Episode: 1913, Score: -8.0, Avg reward: 13.80\n",
      "Episode: 1914, Score: 0.0, Avg reward: 13.78\n",
      "Episode: 1915, Score: 48.0, Avg reward: 13.78\n",
      "Episode: 1916, Score: 12.0, Avg reward: 14.30\n",
      "Episode: 1917, Score: 48.0, Avg reward: 14.90\n",
      "Episode: 1918, Score: 48.0, Avg reward: 15.44\n",
      "Episode: 1919, Score: -10.0, Avg reward: 15.22\n",
      "Episode: 1920, Score: -18.0, Avg reward: 14.56\n",
      "Episode: 1921, Score: 48.0, Avg reward: 14.56\n",
      "Episode: 1922, Score: -32.0, Avg reward: 13.76\n",
      "Episode: 1923, Score: -48.0, Avg reward: 12.80\n",
      "Episode: 1924, Score: -48.0, Avg reward: 11.84\n",
      "Episode: 1925, Score: 20.0, Avg reward: 11.56\n",
      "Episode: 1926, Score: -34.0, Avg reward: 11.18\n",
      "Episode: 1927, Score: -6.0, Avg reward: 11.04\n",
      "Episode: 1928, Score: -4.0, Avg reward: 10.94\n",
      "Episode: 1929, Score: 48.0, Avg reward: 11.72\n",
      "Episode: 1930, Score: 0.0, Avg reward: 11.24\n",
      "Episode: 1931, Score: -26.0, Avg reward: 10.90\n",
      "Episode: 1932, Score: -6.0, Avg reward: 11.14\n",
      "Episode: 1933, Score: -26.0, Avg reward: 11.20\n",
      "Episode: 1934, Score: 2.0, Avg reward: 10.74\n",
      "Episode: 1935, Score: -46.0, Avg reward: 10.30\n",
      "Episode: 1936, Score: 46.0, Avg reward: 10.28\n",
      "Episode: 1937, Score: 24.0, Avg reward: 10.12\n",
      "Episode: 1938, Score: -18.0, Avg reward: 9.94\n",
      "Episode: 1939, Score: 48.0, Avg reward: 9.94\n",
      "Episode: 1940, Score: -44.0, Avg reward: 9.96\n",
      "Episode: 1941, Score: -10.0, Avg reward: 10.00\n",
      "Episode: 1942, Score: -28.0, Avg reward: 9.70\n",
      "Episode: 1943, Score: -20.0, Avg reward: 9.90\n",
      "Episode: 1944, Score: -28.0, Avg reward: 9.14\n",
      "Episode: 1945, Score: -10.0, Avg reward: 8.56\n",
      "Episode: 1946, Score: 48.0, Avg reward: 8.56\n",
      "Episode: 1947, Score: 46.0, Avg reward: 9.14\n",
      "Episode: 1948, Score: -6.0, Avg reward: 9.34\n",
      "Episode: 1949, Score: -12.0, Avg reward: 8.74\n",
      "Episode: 1950, Score: 48.0, Avg reward: 9.44\n",
      "Episode: 1951, Score: -44.0, Avg reward: 8.58\n",
      "Episode: 1952, Score: 48.0, Avg reward: 8.96\n",
      "Episode: 1953, Score: -8.0, Avg reward: 8.60\n",
      "Episode: 1954, Score: -4.0, Avg reward: 8.08\n",
      "Episode: 1955, Score: 48.0, Avg reward: 8.08\n",
      "Episode: 1956, Score: 4.0, Avg reward: 7.82\n",
      "Episode: 1957, Score: -6.0, Avg reward: 7.74\n",
      "Episode: 1958, Score: 0.0, Avg reward: 7.26\n",
      "Episode: 1959, Score: 48.0, Avg reward: 7.26\n",
      "Episode: 1960, Score: -22.0, Avg reward: 6.56\n",
      "Episode: 1961, Score: -12.0, Avg reward: 6.92\n",
      "Episode: 1962, Score: 48.0, Avg reward: 7.54\n",
      "Episode: 1963, Score: 48.0, Avg reward: 7.54\n",
      "Episode: 1964, Score: 4.0, Avg reward: 7.10\n",
      "Episode: 1965, Score: 47.0, Avg reward: 7.91\n",
      "Episode: 1966, Score: 8.0, Avg reward: 7.85\n",
      "Episode: 1967, Score: 4.0, Avg reward: 7.49\n",
      "Episode: 1968, Score: -6.0, Avg reward: 7.83\n",
      "Episode: 1969, Score: 48.0, Avg reward: 7.91\n",
      "Episode: 1970, Score: 48.0, Avg reward: 8.47\n",
      "Episode: 1971, Score: -38.0, Avg reward: 7.61\n",
      "Episode: 1972, Score: 48.0, Avg reward: 8.01\n",
      "Episode: 1973, Score: -4.0, Avg reward: 8.19\n",
      "Episode: 1974, Score: -24.0, Avg reward: 7.47\n",
      "Episode: 1975, Score: -24.0, Avg reward: 7.31\n",
      "Episode: 1976, Score: -16.0, Avg reward: 7.63\n",
      "Episode: 1977, Score: -34.0, Avg reward: 7.19\n",
      "Episode: 1978, Score: -2.0, Avg reward: 7.41\n",
      "Episode: 1979, Score: 46.0, Avg reward: 8.05\n",
      "Episode: 1980, Score: -22.0, Avg reward: 8.31\n",
      "Episode: 1981, Score: 6.0, Avg reward: 7.89\n",
      "Episode: 1982, Score: -38.0, Avg reward: 7.25\n",
      "Episode: 1983, Score: 0.0, Avg reward: 7.43\n",
      "Episode: 1984, Score: 2.0, Avg reward: 7.51\n",
      "Episode: 1985, Score: 8.0, Avg reward: 7.11\n",
      "Episode: 1986, Score: 48.0, Avg reward: 7.91\n",
      "Episode: 1987, Score: 48.0, Avg reward: 8.29\n",
      "Episode: 1988, Score: 30.0, Avg reward: 8.69\n",
      "Episode: 1989, Score: -4.0, Avg reward: 8.19\n",
      "Episode: 1990, Score: 22.0, Avg reward: 8.89\n",
      "Episode: 1991, Score: -46.0, Avg reward: 7.95\n",
      "Episode: 1992, Score: -24.0, Avg reward: 7.23\n",
      "Episode: 1993, Score: 48.0, Avg reward: 7.23\n",
      "Episode: 1994, Score: -8.0, Avg reward: 6.99\n",
      "Episode: 1995, Score: 12.0, Avg reward: 7.13\n",
      "Episode: 1996, Score: -4.0, Avg reward: 7.31\n",
      "Episode: 1997, Score: -34.0, Avg reward: 6.51\n",
      "Episode: 1998, Score: -6.0, Avg reward: 6.51\n",
      "Episode: 1999, Score: -14.0, Avg reward: 6.35\n"
     ]
    }
   ],
   "source": [
    "networks = [TFQNetwork, PTQNetwork]\n",
    "agent = DQNAgent(state_size, action_size, network=networks[0], eps=1.0, load=False)\n",
    "\n",
    "scores = []\n",
    "scores_buffer = deque(maxlen=100)\n",
    "avg_scores = []\n",
    "num_episodes = 2000\n",
    "for ep in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        agent.train(state, action, next_state, reward, done)\n",
    "        total_reward += reward  \n",
    "        state = next_state \n",
    "\n",
    "    scores.append(total_reward)\n",
    "    scores_buffer.append(total_reward)\n",
    "    avg_scores.append(np.mean(scores_buffer))\n",
    "    if avg_scores[-1] >= np.max(avg_scores): agent.q_network.save_model()\n",
    "    print(\"Episode: {}, Score: {}, Avg reward: {:.2f}\".format(ep, scores[-1], avg_scores[-1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Plotting the training rewards\n",
    "\n",
    "The plot below shows the total reward from each episode (blue) and the average reward over the last 100 episodes (orange). We can see that the agent was able to reach the average reward of 20 after about 1750 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1138ec320>,\n",
       " <matplotlib.lines.Line2D at 0x1138ec588>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = range(len(scores))\n",
    "plt.plot(x,scores, x,avg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test the Agent\n",
    "\n",
    "The cell below creates a test agent loading the trained weights for a test run of the environment with the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Score: 18\n"
     ]
    }
   ],
   "source": [
    "test_agent = DQNAgent(state_size, action_size, load=True)\n",
    "state = env.reset(train_mode=False)\n",
    "total_reward = 0\n",
    "done = False\n",
    "while not done:\n",
    "    action = test_agent.get_action(state, eps=0.0)\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    total_reward += reward  \n",
    "    state = next_state \n",
    "print(\"Score: {}\".format(total_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Close the environment when finished\n",
    "When we are finished using an environment, we can close it with the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
